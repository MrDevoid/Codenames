{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0e57f",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5776d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "470ce8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spa or eng\n",
    "language = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8840463",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_words = [\"abogado\",\"aceite\",\"áfrica\",\"agente\",\"agua\",\"águila\",\"aguja\",\"agujero\",\"aire\",\"alemania\",\"algodón\",\"alianza\",\"alpes\",\"ambulancia\",\"américa\",\"ángel\",\"anillo\",\"antártida\",\"antorcha\",\"araña\",\"archivo\",\"arco\",\"argentina\",\"artículo\",\"as\",\"atlántida\",\"azteca\",\"baile\",\"bala\",\"ballena\",\"banco\",\"banda\",\"baño\",\"barco\",\"barra\",\"batería\",\"berlín\",\"bermudas\",\"bicho\",\"blanco\",\"bloque\",\"boca\",\"bola\",\"bolsa\",\"bomba\",\"bosque\",\"bota\",\"botella\",\"botón\",\"brazo\",\"bruja\",\"caballero\",\"caballo\",\"cabeza\",\"cabina\",\"cabo\",\"cactus\",\"cadena\",\"caja\",\"cama\",\"cámara\",\"cambio\",\"campana\",\"campo\",\"canal\",\"canguro\",\"canto\",\"caña\",\"capa\",\"capital\",\"caqui\",\"cara\",\"caravana\",\"carga\",\"carrera\",\"carro\",\"carta\",\"casco\",\"casino\",\"caza\",\"cementerio\",\"centauro\",\"centro\",\"cervantes\",\"checo\",\"chocolate\",\"choque\",\"chuleta\",\"científico\",\"cinta\",\"cinturón\",\"círculo\",\"clase\",\"coche\",\"cocinero\",\"coco\",\"código\",\"cola\",\"cólera\",\"columna\",\"cometa\",\"compás\",\"concierto\",\"conejo\",\"contrabandista\",\"copa\",\"corazón\",\"corneta\",\"corona\",\"corredor\",\"corriente\",\"corte\",\"cresta\",\"cromo\",\"cruz\",\"cuadro\",\"cuarto\",\"cubierta\",\"cubo\",\"cuchillo\",\"cuello\",\"cuerda\",\"cuerno\",\"cura\",\"dama\",\"delta\",\"destino\",\"día\",\"diamante\",\"diana\",\"diario\",\"diente\",\"dinosaurio\",\"disco\",\"don\",\"dragón\",\"duende\",\"egipto\",\"embajada\",\"emperador\",\"enano\",\"enfermedad\",\"enfermera\",\"enlace\",\"escorpión\",\"espacio\",\"espía\",\"estación\",\"estadio\",\"estado\",\"estrella\",\"estudio\",\"etiqueta\",\"europa\",\"extraterrestre\",\"falda\",\"fantasma\",\"faro\",\"ficha\",\"fiesta\",\"figura\",\"flauta\",\"flecha\",\"foso\",\"francia\",\"frente\",\"fuego\",\"fuente\",\"fuerza\",\"furgoneta\",\"gancho\",\"gato\",\"genio\",\"gigante\",\"golfo\",\"golondrina\",\"golpe\",\"goma\",\"góndola\",\"gota\",\"grado\",\"granada\",\"grano\",\"grecia\",\"grifo\",\"guante\",\"guardia\",\"guerra\",\"gusano\",\"helado\",\"helicóptero\",\"hielo\",\"hierba\",\"hoja\",\"hollywood\",\"horca\",\"hospital\",\"hotel\",\"iglesia\",\"imán\",\"india\",\"índice\",\"inglaterra\",\"italia\",\"jarra\",\"judía\",\"juicio\",\"kiwi\",\"ladrón\",\"lago ness\",\"láser\",\"látigo\",\"lengua\",\"león\",\"libra\",\"lima\",\"limusina\",\"línea\",\"lista\",\"llama\",\"llave\",\"lomo\",\"londres\",\"luna\",\"luz\",\"maestro\",\"magia\",\"malta\",\"mancha\",\"mando\",\"manga\",\"mango\",\"mano\",\"manzana\",\"mañana\",\"marca\",\"marcha\",\"marfil\",\"masa\",\"máscara\",\"mazo\",\"médico\",\"mercurio\",\"mesa\",\"metro\",\"méxico\",\"micro\",\"microscopi\",\"mielo\",\"millonario\",\"mina\",\"misil\",\"modelo\",\"módulo\",\"monitor\",\"mono\",\"mortero\",\"moscú\",\"motor\",\"muelle\",\"muerte\",\"muñeca\",\"muro\",\"naranja\",\"nave\",\"nieve\",\"nilo\",\"ninja\",\"noche\",\"nota\",\"nudo\",\"nueva york\",\"obra\",\"ojo\",\"ola\",\"olimpo\",\"ópera\",\"orden\",\"órgano\",\"ornitorrinco\",\"oro\",\"oso\",\"pala\",\"palma\",\"pantalla\",\"papel\",\"paracaídas\",\"pase\",\"paso\",\"pasta\",\"pastel\",\"pavo\",\"pekín\",\"película\",\"pelotón\",\"pendiente\",\"perro\",\"pez\",\"pico\",\"pie\",\"pieza\",\"pila\",\"piloto\",\"pincho\",\"pingüino\",\"pinta\",\"piña\",\"pirámide\",\"pirata\",\"pista\",\"pistola\",\"placa\",\"plano\",\"planta\",\"plátano\",\"playa\",\"plomo\",\"pluma\",\"policía\",\"polo\",\"portada\",\"portero\",\"potro\",\"prensa\",\"prima\",\"princesa\",\"puente\",\"puerto\",\"pulpo\",\"pulso\",\"punta\",\"punto\",\"radio\",\"rascacielos\",\"ratón\",\"rayo\",\"red\",\"regla\",\"reina\",\"reserva\",\"revolución\",\"rey\",\"robot\",\"rojo\",\"roma\",\"ronda\",\"rosa\",\"ruleta\",\"sable\",\"sáhara\",\"salsa\",\"satélite\",\"saturno\",\"señal\",\"serie\",\"serpiente\",\"sierra\",\"silla\",\"sirena\",\"sobre\",\"soldado\",\"submarinista\",\"suerte\",\"superhéroe\",\"tabla\",\"tableta\",\"taco\",\"tacto\",\"talón\",\"tanque\",\"tapa\",\"tarde\",\"teatro\",\"teclado\",\"telescopio\",\"testigo\",\"tiempo\",\"tienda\",\"tierra\",\"tokio\",\"topo\",\"torre\",\"trama\",\"tronco\",\"tubería\",\"tubo\",\"unicornio\",\"vacío\",\"vado\",\"vampiro\",\"vela\",\"veneno\",\"venus\",\"vestido\",\"vida\",\"vidrio\",\"viento\",\"yema\",\"zanahoria\",\"zapato\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90dda6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = [\"AFRICA\",\"AGENT\",\"AIR\",\"ALIEN\",\"ALPS\",\"AMAZON\",\"AMBULANCE\",\"AMERICA\",\"ANGEL\",\"ANTARCTICA\",\"APPLE\",\"ARM\",\"ATLANTIS\",\"AUSTRALIA\",\"AZTEC\",\"BACK\",\"BALL\",\"BAND\",\"BANK\",\"BAR\",\"BARK\",\"BAT\",\"BATTERY\",\"BEACH\",\"BEAR\",\"BEAT\",\"BED\",\"BEIJING\",\"BELL\",\"BELT\",\"BERLIN\",\"BERMUDA\",\"BERRY\",\"BILL\",\"BLOCK\",\"BOARD\",\"BOLT\",\"BOMB\",\"BOND\",\"BOOM\",\"BOOT\",\"BOTTLE\",\"BOW\",\"BOX\",\"BRIDGE\",\"BRUSH\",\"BUCK\",\"BUFFALO\",\"BUG\",\"BUGLE\",\"BUTTON\",\"CALF\",\"CANADA\",\"CAP\",\"CAPITAL\",\"CAR\",\"CARD\",\"CARROT\",\"CASINO\",\"CAST\",\"CAT\",\"CELL\",\"CENTAUR\",\"CENTER\",\"CHAIR\",\"CHANGE\",\"CHARGE\",\"CHECK\",\"CHEST\",\"CHICK\",\"CHINA\",\"CHOCOLATE\",\"CHURCH\",\"CIRCLE\",\"CLIFF\",\"CLOAK\",\"CLUB\",\"CODE\",\"COLD\",\"COMIC\",\"COMPOUND\",\"CONCERT\",\"CONDUCTOR\",\"CONTRACT\",\"COOK\",\"COPPER\",\"COTTON\",\"COURT\",\"COVER\",\"CRANE\",\"CRASH\",\"CRICKET\",\"CROSS\",\"CROWN\",\"CYCLE\",\"CZECH\",\"DANCE\",\"DATE\",\"DAY\",\"DEATH\",\"DECK\",\"DEGREE\",\"DIAMOND\",\"DICE\",\"DINOSAUR\",\"DISEASE\",\"DOCTOR\",\"DOG\",\"DRAFT\",\"DRAGON\",\"DRESS\",\"DRILL\",\"DROP\",\"DUCK\",\"DWARF\",\"EAGLE\",\"EGYPT\",\"EMBASSY\",\"ENGINE\",\"ENGLAND\",\"EUROPE\",\"EYE\",\"FACE\",\"FAIR\",\"FALL\",\"FAN\",\"FENCE\",\"FIELD\",\"FIGHTER\",\"FIGURE\",\"FILE\",\"FILM\",\"FIRE\",\"FISH\",\"FLUTE\",\"FLY\",\"FOOT\",\"FORCE\",\"FOREST\",\"FORK\",\"FRANCE\",\"GAME\",\"GAS\",\"GENIUS\",\"GERMANY\",\"GHOST\",\"GIANT\",\"GLASS\",\"GLOVE\",\"GOLD\",\"GRACE\",\"GRASS\",\"GREECE\",\"GREEN\",\"GROUND\",\"HAM\",\"HAND\",\"HAWK\",\"HEAD\",\"HEART\",\"HELICOPTER\",\"HIMALAYAS\",\"HOLE\",\"HOLLYWOOD\",\"HONEY\",\"HOOD\",\"HOOK\",\"HORN\",\"HORSE\",\"HORSESHOE\",\"HOSPITAL\",\"HOTEL\",\"ICE\",\"ICE CREAM\",\"INDIA\",\"IRON\",\"IVORY\",\"JACK\",\"JAM\",\"JET\",\"JUPITER\",\"KANGAROO\",\"KETCHUP\",\"KEY\",\"KID\",\"KING\",\"KIWI\",\"KNIFE\",\"KNIGHT\",\"LAB\",\"LAP\",\"LASER\",\"LAWYER\",\"LEAD\",\"LEMON\",\"LEPRECHAUN\",\"LIFE\",\"LIGHT\",\"LIMOUSINE\",\"LINE\",\"LINK\",\"LION\",\"LITTER\",\"LOCH NESS\",\"LOCK\",\"LOG\",\"LONDON\",\"LUCK\",\"MAIL\",\"MAMMOTH\",\"MAPLE\",\"MARBLE\",\"MARCH\",\"MASS\",\"MATCH\",\"MERCURY\",\"MEXICO\",\"MICROSCOPE\",\"MILLIONAIRE\",\"MINE\",\"MINT\",\"MISSILE\",\"MODEL\",\"MOLE\",\"MOON\",\"MOSCOW\",\"MOUNT\",\"MOUSE\",\"MOUTH\",\"MUG\",\"NAIL\",\"NEEDLE\",\"NET\",\"NEW YORK\",\"NIGHT\",\"NINJA\",\"NOTE\",\"NOVEL\",\"NURSE\",\"NUT\",\"OCTOPUS\",\"OIL\",\"OLIVE\",\"OLYMPUS\",\"OPERA\",\"ORANGE\",\"ORGAN\",\"PALM\",\"PAN\",\"PANTS\",\"PAPER\",\"PARACHUTE\",\"PARK\",\"PART\",\"PASS\",\"PASTE\",\"PENGUIN\",\"PHOENIX\",\"PIANO\",\"PIE\",\"PILOT\",\"PIN\",\"PIPE\",\"PIRATE\",\"PISTOL\",\"PIT\",\"PITCH\",\"PLANE\",\"PLASTIC\",\"PLATE\",\"PLATYPUS\",\"PLAY\",\"PLOT\",\"POINT\",\"POISON\",\"POLE\",\"POLICE\",\"POOL\",\"PORT\",\"POST\",\"POUND\",\"PRESS\",\"PRINCESS\",\"PUMPKIN\",\"PUPIL\",\"PYRAMID\",\"QUEEN\",\"RABBIT\",\"RACKET\",\"RAY\",\"REVOLUTION\",\"RING\",\"ROBIN\",\"ROBOT\",\"ROCK\",\"ROME\",\"ROOT\",\"ROSE\",\"ROULETTE\",\"ROUND\",\"ROW\",\"RULER\",\"SATELLITE\",\"SATURN\",\"SCALE\",\"SCHOOL\",\"SCIENTIST\",\"SCORPION\",\"SCREEN\",\"SCUBA DIVER\",\"SEAL\",\"SERVER\",\"SHADOW\",\"SHAKESPEARE\",\"SHARK\",\"SHIP\",\"SHOE\",\"SHOP\",\"SHOT\",\"SINK\",\"SKYSCRAPER\",\"SLIP\",\"SLUG\",\"SMUGGLER\",\"SNOW\",\"SNOWMAN\",\"SOCK\",\"SOLDIER\",\"SOUL\",\"SOUND\",\"SPACE\",\"SPELL\",\"SPIDER\",\"SPIKE\",\"SPINE\",\"SPOT\",\"SPRING\",\"SPY\",\"SQUARE\",\"STADIUM\",\"STAFF\",\"STAR\",\"STATE\",\"STICK\",\"STOCK\",\"STRAW\",\"STREAM\",\"STRIKE\",\"STRING\",\"SUB\",\"SUIT\",\"SUPERHERO\",\"SWING\",\"SWITCH\",\"TABLE\",\"TABLET\",\"TAG\",\"TAIL\",\"TAP\",\"TEACHER\",\"TELESCOPE\",\"TEMPLE\",\"THEATER\",\"THIEF\",\"THUMB\",\"TICK\",\"TIE\",\"TIME\",\"TOKYO\",\"TOOTH\",\"TORCH\",\"TOWER\",\"TRACK\",\"TRAIN\",\"TRIANGLE\",\"TRIP\",\"TRUNK\",\"TUBE\",\"TURKEY\",\"UNDERTAKER\",\"UNICORN\",\"VACUUM\",\"VAN\",\"VET\",\"WAKE\",\"WALL\",\"WAR\",\"WASHER\",\"WASHINGTON\",\"WATCH\",\"WATER\",\"WAVE\",\"WEB\",\"WELL\",\"WHALE\",\"WHIP\",\"WIND\",\"WITCH\",\"WORM\",\"YARD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a369ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import gensim\n",
    "import nltk\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ca8c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e926058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    fasttext.util.download_model('es', if_exists='ignore')  # English\n",
    "else:\n",
    "    fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51a78d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if language == \"spa\":\n",
    "    FAST_TEXT_MODEL = \"cc.es.300.bin\" # Model name in fasttext\n",
    "else:\n",
    "    FAST_TEXT_MODEL = \"cc.en.300.bin\"\n",
    "\n",
    "\n",
    "ft = fasttext.load_model(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b57af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_facebook_model(FAST_TEXT_MODEL)\n",
    "#model.wv.most_similar(positive=['red', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "187f23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    words = spanish_words \n",
    "else: \n",
    "    words = english_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884caf7",
   "metadata": {},
   "source": [
    "# Medias entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00b7db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    return model.wv.similarity(word1, word2)\n",
    "\n",
    "def get_synonyms(word1, lang = 'spa'):\n",
    "    all_synonyms = list(map(lambda x: x.lemma_names(lang), wn.synsets(word1, lang=lang)))\n",
    "    return list(set(itertools.chain(*all_synonyms)))\n",
    "\n",
    "def get_antonyms(word1, lang = 'spa'):\n",
    "    all_lemas = list(map(lambda x: x.lemmas(), wn.synsets(word1, lang=lang)))\n",
    "    all_antonyms_lemas = list(map(lambda x: x.antonyms(), list(itertools.chain(*all_lemas))))\n",
    "    all_antonyms = map(lambda x: x.synset().lemma_names(lang=lang), list(itertools.chain(*all_antonyms_lemas)))\n",
    "    return list(set(itertools.chain(*all_antonyms)))\n",
    "\n",
    "def get_synonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_synonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_synonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    synonyms = list(set(synonyms_word1).intersection(synonyms_word2))\n",
    "    if len(synonyms) !=0:\n",
    "        max_value = max(synonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_number_of_same_synonyms(word1, word2, lang = 'spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_number_of_same_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    return len(set(antonyms_word1).intersection(antonyms_word2))\n",
    "\n",
    "def get_number_synonyms_vs_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(antonyms_word2)) + len(set(antonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_antonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_antonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_antonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    antonyms = list(set(antonyms_word1).intersection(antonyms_word2))\n",
    "    if len(antonyms) != 0:\n",
    "        max_value = max(antonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_hypernyms_of_synsets(synsets):\n",
    "    hypernyms = list(map(lambda x: x.hypernyms(), synsets))\n",
    "    return list(set(itertools.chain(*hypernyms)))\n",
    "\n",
    "def get_path_similarity(synset1, synset2):\n",
    "    similarity = wn.path_similarity(synset1, synset2)\n",
    "    similarity = similarity if similarity else 0\n",
    "    return similarity\n",
    "\n",
    "def get_first_common_hypernym(word1, word2, lang = 'spa'):\n",
    "    temporal_hypernyms1 = get_hypernyms_of_synsets(wn.synsets(word1, lang=lang))\n",
    "    temporal_hypernyms2 = get_hypernyms_of_synsets(wn.synsets(word2, lang=lang))\n",
    "    hypernyms1 = list(set(temporal_hypernyms1))\n",
    "    hypernyms2 = list(set(temporal_hypernyms2))\n",
    "    while len(set(hypernyms1).intersection(hypernyms2))==0 and (len(temporal_hypernyms1)!=0 or len(temporal_hypernyms2)!=0):\n",
    "        hypernyms1 = list(set(hypernyms1 + temporal_hypernyms1))\n",
    "        hypernyms2 = list(set(hypernyms2 + temporal_hypernyms2))\n",
    "        temporal_hypernyms1 = get_hypernyms_of_synsets(temporal_hypernyms1)\n",
    "        temporal_hypernyms2 = get_hypernyms_of_synsets(temporal_hypernyms2)\n",
    "    if len(set(hypernyms1).intersection(hypernyms2))!=0:\n",
    "        hypernyms = list(set(hypernyms1).intersection(hypernyms2))\n",
    "        possible_hypernyms = list(map(lambda x: max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word1, lang=lang)))) + max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word2, lang=lang)))),hypernyms))\n",
    "        max_value = max(possible_hypernyms)\n",
    "        hypernym = hypernyms[possible_hypernyms.index(max_value)]\n",
    "        similarity_to_word1 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word1, lang=lang))))\n",
    "        similarity_to_word2 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word2, lang=lang))))\n",
    "    else:\n",
    "        hypernym = None\n",
    "        similarity_to_word1 = 0\n",
    "        similarity_to_word2 = 0\n",
    "    return hypernym, similarity_to_word1, similarity_to_word2\n",
    "    \n",
    "    \n",
    "def apply_all_metrics_to_words_df(df, model, word2, lang = 'spa'):\n",
    "    df['similarity'] = df.apply(lambda x: get_cosine_similarity(model, x['words'], word2), axis=1)\n",
    "    df['number_same_synonyms'] = df.apply(lambda x: get_number_of_same_synonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['number_same_antonyms'] = df.apply(lambda x: get_number_of_same_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['synonyms_vs_antonyms'] = df.apply(lambda x: get_number_synonyms_vs_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['max_similarity_synonym'] = df.apply(lambda x: get_max_synonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['max_similarity_antonym'] = df.apply(lambda x: get_max_antonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['distance_common_hypernym'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[1], axis=1)\n",
    "    df['distance_common_hypernym_from_word'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[2], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_definition(word, lang = 'spa'):\n",
    "    return list(map(lambda x: x.definition(),wn.synsets(word, lang= lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a6cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.es.300.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.download_model('es', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaabf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grado similaridad\n",
    "#Numero de sinonimos en común\n",
    "#Número de antónimos en común\n",
    "#Relación con los sinonimos\n",
    "#Relación con los antónimos\n",
    "#Familia semántica (Hiperonimos)\n",
    "#Número de palabras entre la pista y la evaluada(s)\n",
    "\n",
    "\n",
    "# Implementar distancia de la definiciones\n",
    "# Hacer clustering (jerarquico y k-means)\n",
    "# Implementar bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(words, columns = [\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf83b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb01bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_all_metrics_to_words_df(sample_data, model, 'dinero', lang=language)\n",
    "df.index = df.words\n",
    "df = df.drop(['words'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb799d",
   "metadata": {},
   "source": [
    "# Vectores como variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea26a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector(words, clue):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = pd.DataFrame(words, columns = [\"words\"], index=words)\n",
    "    df_with_vectors[column_names] = df_with_vectors.apply(lambda x: list(ft.get_word_vector(x['words'])), axis=1, result_type='expand')\n",
    "    df_with_vectors = df_with_vectors.drop(['words'], axis=1)\n",
    "    df_with_vectors_and_clue = pd.concat([df_with_vectors, pd.DataFrame([list(ft.get_word_vector(clue))], index=[clue], columns=column_names)])\n",
    "    return df_with_vectors_and_clue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea89d0e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b900428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YARD' 'MAPLE' 'AGENT' 'DEATH' 'FALL' 'STADIUM' 'GENIUS' 'DISEASE' 'DROP'\n",
      " 'SNOWMAN' 'BERLIN' 'HOOK' 'GREEN' 'HORSESHOE' 'SPRING' 'ALPS' 'FORK'\n",
      " 'BEAR' 'WATER' 'SHIP' 'SMUGGLER' 'TAP' 'CHANGE' 'NOTE' 'THEATER']\n"
     ]
    }
   ],
   "source": [
    "sample_words = np.random.choice(words, size=25, replace=False)\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "403728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(v1, v2):\n",
    "    return np.sqrt(np.sum(np.subtract(v1, v2)**2))\n",
    "\n",
    "def get_words_from_clue(sample_words, clue, number_words, model):\n",
    "    return list(filter(lambda element: element!= clue, list(get_dataframe_from_clue(sample_words, clue, number_words, model)[:number_words+1].index)))\n",
    "    \n",
    "\n",
    "def get_dataframe_from_clue(sample_words, clue, number_words, model):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector(sample_words, clue)\n",
    "    kmeans = KMeans(n_clusters = 25 - number_words)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    clue_cluster = kmeans_response.cluster_centers_[df_for_clustering['cluster'][-1]]\n",
    "    distance_to_clue_cluster = list(map(lambda center: get_distance(center, clue_cluster), kmeans_response.cluster_centers_))\n",
    "    df_for_clustering['distance_to_clue_cluster'] = df_for_clustering.apply(lambda cluster: distance_to_clue_cluster[int(cluster['cluster'])], axis=1)\n",
    "    df_for_clustering['distance_to_clue'] = df_for_clustering.apply(lambda row: 1-model.wv.similarity(row.name, clue), axis=1)\n",
    "    return df_for_clustering[['cluster', 'distance_to_clue_cluster', 'distance_to_clue']].sort_values(by=['distance_to_clue_cluster', 'distance_to_clue'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d23215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "clue='FOOTBALL'\n",
    "number_words = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "287b5fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STADIUM', 'HORSESHOE']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a209c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>distance_to_clue_cluster</th>\n",
       "      <th>distance_to_clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOOTBALL</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORSESHOE</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENIUS</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMUGGLER</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNOWMAN</th>\n",
       "      <td>22</td>\n",
       "      <td>0.913052</td>\n",
       "      <td>0.670487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THEATER</th>\n",
       "      <td>1</td>\n",
       "      <td>0.921925</td>\n",
       "      <td>0.612628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANGE</th>\n",
       "      <td>20</td>\n",
       "      <td>0.937361</td>\n",
       "      <td>0.665874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPRING</th>\n",
       "      <td>10</td>\n",
       "      <td>0.954889</td>\n",
       "      <td>0.558790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISEASE</th>\n",
       "      <td>21</td>\n",
       "      <td>0.991137</td>\n",
       "      <td>0.737698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STADIUM</th>\n",
       "      <td>19</td>\n",
       "      <td>1.002600</td>\n",
       "      <td>0.457189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREEN</th>\n",
       "      <td>18</td>\n",
       "      <td>1.065309</td>\n",
       "      <td>0.633721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEATH</th>\n",
       "      <td>16</td>\n",
       "      <td>1.105866</td>\n",
       "      <td>0.621445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WATER</th>\n",
       "      <td>15</td>\n",
       "      <td>1.145979</td>\n",
       "      <td>0.614646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERLIN</th>\n",
       "      <td>14</td>\n",
       "      <td>1.185389</td>\n",
       "      <td>0.681153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPLE</th>\n",
       "      <td>11</td>\n",
       "      <td>1.407801</td>\n",
       "      <td>0.714204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOTE</th>\n",
       "      <td>12</td>\n",
       "      <td>1.464643</td>\n",
       "      <td>0.743331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FALL</th>\n",
       "      <td>17</td>\n",
       "      <td>1.493967</td>\n",
       "      <td>0.532150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEAR</th>\n",
       "      <td>3</td>\n",
       "      <td>1.684154</td>\n",
       "      <td>0.645121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DROP</th>\n",
       "      <td>9</td>\n",
       "      <td>1.693030</td>\n",
       "      <td>0.684197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YARD</th>\n",
       "      <td>7</td>\n",
       "      <td>1.744876</td>\n",
       "      <td>0.569015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHIP</th>\n",
       "      <td>13</td>\n",
       "      <td>1.748425</td>\n",
       "      <td>0.718288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOOK</th>\n",
       "      <td>8</td>\n",
       "      <td>1.773893</td>\n",
       "      <td>0.671690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALPS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.800985</td>\n",
       "      <td>0.872490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORK</th>\n",
       "      <td>6</td>\n",
       "      <td>1.867244</td>\n",
       "      <td>0.648931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGENT</th>\n",
       "      <td>5</td>\n",
       "      <td>2.191105</td>\n",
       "      <td>0.848066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAP</th>\n",
       "      <td>4</td>\n",
       "      <td>2.271703</td>\n",
       "      <td>0.718675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster  distance_to_clue_cluster  distance_to_clue\n",
       "FOOTBALL         2                  0.000000          0.000000\n",
       "HORSESHOE        2                  0.000000          0.639124\n",
       "GENIUS           2                  0.000000          0.647310\n",
       "SMUGGLER         2                  0.000000          0.707211\n",
       "SNOWMAN         22                  0.913052          0.670487\n",
       "THEATER          1                  0.921925          0.612628\n",
       "CHANGE          20                  0.937361          0.665874\n",
       "SPRING          10                  0.954889          0.558790\n",
       "DISEASE         21                  0.991137          0.737698\n",
       "STADIUM         19                  1.002600          0.457189\n",
       "GREEN           18                  1.065309          0.633721\n",
       "DEATH           16                  1.105866          0.621445\n",
       "WATER           15                  1.145979          0.614646\n",
       "BERLIN          14                  1.185389          0.681153\n",
       "MAPLE           11                  1.407801          0.714204\n",
       "NOTE            12                  1.464643          0.743331\n",
       "FALL            17                  1.493967          0.532150\n",
       "BEAR             3                  1.684154          0.645121\n",
       "DROP             9                  1.693030          0.684197\n",
       "YARD             7                  1.744876          0.569015\n",
       "SHIP            13                  1.748425          0.718288\n",
       "HOOK             8                  1.773893          0.671690\n",
       "ALPS             0                  1.800985          0.872490\n",
       "FORK             6                  1.867244          0.648931\n",
       "AGENT            5                  2.191105          0.848066\n",
       "TAP              4                  2.271703          0.718675"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataframe_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7805129f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-codenames",
   "language": "python",
   "name": "py-codenames"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
