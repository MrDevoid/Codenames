{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0e57f",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470ce8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spa or eng\n",
    "SPANISH = 'spa'\n",
    "ENGLISH = 'eng'\n",
    "language = SPANISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8840463",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_words = [\"abogado\",\"aceite\",\"áfrica\",\"agente\",\"agua\",\"águila\",\"aguja\",\"agujero\",\"aire\",\"alemania\",\"algodón\",\"alianza\",\"alpes\",\"ambulancia\",\"américa\",\"ángel\",\"anillo\",\"antártida\",\"antorcha\",\"araña\",\"archivo\",\"arco\",\"argentina\",\"artículo\",\"as\",\"atlántida\",\"azteca\",\"baile\",\"bala\",\"ballena\",\"banco\",\"banda\",\"baño\",\"barco\",\"barra\",\"batería\",\"berlín\",\"bermudas\",\"bicho\",\"blanco\",\"bloque\",\"boca\",\"bola\",\"bolsa\",\"bomba\",\"bosque\",\"bota\",\"botella\",\"botón\",\"brazo\",\"bruja\",\"caballero\",\"caballo\",\"cabeza\",\"cabina\",\"cabo\",\"cactus\",\"cadena\",\"caja\",\"cama\",\"cámara\",\"cambio\",\"campana\",\"campo\",\"canal\",\"canguro\",\"canto\",\"caña\",\"capa\",\"capital\",\"caqui\",\"cara\",\"caravana\",\"carga\",\"carrera\",\"carro\",\"carta\",\"casco\",\"casino\",\"caza\",\"cementerio\",\"centauro\",\"centro\",\"cervantes\",\"checo\",\"chocolate\",\"choque\",\"chuleta\",\"científico\",\"cinta\",\"cinturón\",\"círculo\",\"clase\",\"coche\",\"cocinero\",\"coco\",\"código\",\"cola\",\"cólera\",\"columna\",\"cometa\",\"compás\",\"concierto\",\"conejo\",\"contrabandista\",\"copa\",\"corazón\",\"corneta\",\"corona\",\"corredor\",\"corriente\",\"corte\",\"cresta\",\"cromo\",\"cruz\",\"cuadro\",\"cuarto\",\"cubierta\",\"cubo\",\"cuchillo\",\"cuello\",\"cuerda\",\"cuerno\",\"cura\",\"dama\",\"delta\",\"destino\",\"día\",\"diamante\",\"diana\",\"diario\",\"diente\",\"dinosaurio\",\"disco\",\"don\",\"dragón\",\"duende\",\"egipto\",\"embajada\",\"emperador\",\"enano\",\"enfermedad\",\"enfermera\",\"enlace\",\"escorpión\",\"espacio\",\"espía\",\"estación\",\"estadio\",\"estado\",\"estrella\",\"estudio\",\"etiqueta\",\"europa\",\"extraterrestre\",\"falda\",\"fantasma\",\"faro\",\"ficha\",\"fiesta\",\"figura\",\"flauta\",\"flecha\",\"foso\",\"francia\",\"frente\",\"fuego\",\"fuente\",\"fuerza\",\"furgoneta\",\"gancho\",\"gato\",\"genio\",\"gigante\",\"golfo\",\"golondrina\",\"golpe\",\"goma\",\"góndola\",\"gota\",\"grado\",\"granada\",\"grano\",\"grecia\",\"grifo\",\"guante\",\"guardia\",\"guerra\",\"gusano\",\"helado\",\"helicóptero\",\"hielo\",\"hierba\",\"hoja\",\"hollywood\",\"horca\",\"hospital\",\"hotel\",\"iglesia\",\"imán\",\"india\",\"índice\",\"inglaterra\",\"italia\",\"jarra\",\"judía\",\"juicio\",\"kiwi\",\"ladrón\",\"lago ness\",\"láser\",\"látigo\",\"lengua\",\"león\",\"libra\",\"lima\",\"limusina\",\"línea\",\"lista\",\"llama\",\"llave\",\"lomo\",\"londres\",\"luna\",\"luz\",\"maestro\",\"magia\",\"malta\",\"mancha\",\"mando\",\"manga\",\"mango\",\"mano\",\"manzana\",\"mañana\",\"marca\",\"marcha\",\"marfil\",\"masa\",\"máscara\",\"mazo\",\"médico\",\"mercurio\",\"mesa\",\"metro\",\"méxico\",\"micro\",\"microscopi\",\"mielo\",\"millonario\",\"mina\",\"misil\",\"modelo\",\"módulo\",\"monitor\",\"mono\",\"mortero\",\"moscú\",\"motor\",\"muelle\",\"muerte\",\"muñeca\",\"muro\",\"naranja\",\"nave\",\"nieve\",\"nilo\",\"ninja\",\"noche\",\"nota\",\"nudo\",\"nueva york\",\"obra\",\"ojo\",\"ola\",\"olimpo\",\"ópera\",\"orden\",\"órgano\",\"ornitorrinco\",\"oro\",\"oso\",\"pala\",\"palma\",\"pantalla\",\"papel\",\"paracaídas\",\"pase\",\"paso\",\"pasta\",\"pastel\",\"pavo\",\"pekín\",\"película\",\"pelotón\",\"pendiente\",\"perro\",\"pez\",\"pico\",\"pie\",\"pieza\",\"pila\",\"piloto\",\"pincho\",\"pingüino\",\"pinta\",\"piña\",\"pirámide\",\"pirata\",\"pista\",\"pistola\",\"placa\",\"plano\",\"planta\",\"plátano\",\"playa\",\"plomo\",\"pluma\",\"policía\",\"polo\",\"portada\",\"portero\",\"potro\",\"prensa\",\"prima\",\"princesa\",\"puente\",\"puerto\",\"pulpo\",\"pulso\",\"punta\",\"punto\",\"radio\",\"rascacielos\",\"ratón\",\"rayo\",\"red\",\"regla\",\"reina\",\"reserva\",\"revolución\",\"rey\",\"robot\",\"rojo\",\"roma\",\"ronda\",\"rosa\",\"ruleta\",\"sable\",\"sáhara\",\"salsa\",\"satélite\",\"saturno\",\"señal\",\"serie\",\"serpiente\",\"sierra\",\"silla\",\"sirena\",\"sobre\",\"soldado\",\"submarinista\",\"suerte\",\"superhéroe\",\"tabla\",\"tableta\",\"taco\",\"tacto\",\"talón\",\"tanque\",\"tapa\",\"tarde\",\"teatro\",\"teclado\",\"telescopio\",\"testigo\",\"tiempo\",\"tienda\",\"tierra\",\"tokio\",\"topo\",\"torre\",\"trama\",\"tronco\",\"tubería\",\"tubo\",\"unicornio\",\"vacío\",\"vado\",\"vampiro\",\"vela\",\"veneno\",\"venus\",\"vestido\",\"vida\",\"vidrio\",\"viento\",\"yema\",\"zanahoria\",\"zapato\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dda6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = [\"AFRICA\",\"AGENT\",\"AIR\",\"ALIEN\",\"ALPS\",\"AMAZON\",\"AMBULANCE\",\"AMERICA\",\"ANGEL\",\"ANTARCTICA\",\"APPLE\",\"ARM\",\"ATLANTIS\",\"AUSTRALIA\",\"AZTEC\",\"BACK\",\"BALL\",\"BAND\",\"BANK\",\"BAR\",\"BARK\",\"BAT\",\"BATTERY\",\"BEACH\",\"BEAR\",\"BEAT\",\"BED\",\"BEIJING\",\"BELL\",\"BELT\",\"BERLIN\",\"BERMUDA\",\"BERRY\",\"BILL\",\"BLOCK\",\"BOARD\",\"BOLT\",\"BOMB\",\"BOND\",\"BOOM\",\"BOOT\",\"BOTTLE\",\"BOW\",\"BOX\",\"BRIDGE\",\"BRUSH\",\"BUCK\",\"BUFFALO\",\"BUG\",\"BUGLE\",\"BUTTON\",\"CALF\",\"CANADA\",\"CAP\",\"CAPITAL\",\"CAR\",\"CARD\",\"CARROT\",\"CASINO\",\"CAST\",\"CAT\",\"CELL\",\"CENTAUR\",\"CENTER\",\"CHAIR\",\"CHANGE\",\"CHARGE\",\"CHECK\",\"CHEST\",\"CHICK\",\"CHINA\",\"CHOCOLATE\",\"CHURCH\",\"CIRCLE\",\"CLIFF\",\"CLOAK\",\"CLUB\",\"CODE\",\"COLD\",\"COMIC\",\"COMPOUND\",\"CONCERT\",\"CONDUCTOR\",\"CONTRACT\",\"COOK\",\"COPPER\",\"COTTON\",\"COURT\",\"COVER\",\"CRANE\",\"CRASH\",\"CRICKET\",\"CROSS\",\"CROWN\",\"CYCLE\",\"CZECH\",\"DANCE\",\"DATE\",\"DAY\",\"DEATH\",\"DECK\",\"DEGREE\",\"DIAMOND\",\"DICE\",\"DINOSAUR\",\"DISEASE\",\"DOCTOR\",\"DOG\",\"DRAFT\",\"DRAGON\",\"DRESS\",\"DRILL\",\"DROP\",\"DUCK\",\"DWARF\",\"EAGLE\",\"EGYPT\",\"EMBASSY\",\"ENGINE\",\"ENGLAND\",\"EUROPE\",\"EYE\",\"FACE\",\"FAIR\",\"FALL\",\"FAN\",\"FENCE\",\"FIELD\",\"FIGHTER\",\"FIGURE\",\"FILE\",\"FILM\",\"FIRE\",\"FISH\",\"FLUTE\",\"FLY\",\"FOOT\",\"FORCE\",\"FOREST\",\"FORK\",\"FRANCE\",\"GAME\",\"GAS\",\"GENIUS\",\"GERMANY\",\"GHOST\",\"GIANT\",\"GLASS\",\"GLOVE\",\"GOLD\",\"GRACE\",\"GRASS\",\"GREECE\",\"GREEN\",\"GROUND\",\"HAM\",\"HAND\",\"HAWK\",\"HEAD\",\"HEART\",\"HELICOPTER\",\"HIMALAYAS\",\"HOLE\",\"HOLLYWOOD\",\"HONEY\",\"HOOD\",\"HOOK\",\"HORN\",\"HORSE\",\"HORSESHOE\",\"HOSPITAL\",\"HOTEL\",\"ICE\",\"ICE CREAM\",\"INDIA\",\"IRON\",\"IVORY\",\"JACK\",\"JAM\",\"JET\",\"JUPITER\",\"KANGAROO\",\"KETCHUP\",\"KEY\",\"KID\",\"KING\",\"KIWI\",\"KNIFE\",\"KNIGHT\",\"LAB\",\"LAP\",\"LASER\",\"LAWYER\",\"LEAD\",\"LEMON\",\"LEPRECHAUN\",\"LIFE\",\"LIGHT\",\"LIMOUSINE\",\"LINE\",\"LINK\",\"LION\",\"LITTER\",\"LOCH NESS\",\"LOCK\",\"LOG\",\"LONDON\",\"LUCK\",\"MAIL\",\"MAMMOTH\",\"MAPLE\",\"MARBLE\",\"MARCH\",\"MASS\",\"MATCH\",\"MERCURY\",\"MEXICO\",\"MICROSCOPE\",\"MILLIONAIRE\",\"MINE\",\"MINT\",\"MISSILE\",\"MODEL\",\"MOLE\",\"MOON\",\"MOSCOW\",\"MOUNT\",\"MOUSE\",\"MOUTH\",\"MUG\",\"NAIL\",\"NEEDLE\",\"NET\",\"NEW YORK\",\"NIGHT\",\"NINJA\",\"NOTE\",\"NOVEL\",\"NURSE\",\"NUT\",\"OCTOPUS\",\"OIL\",\"OLIVE\",\"OLYMPUS\",\"OPERA\",\"ORANGE\",\"ORGAN\",\"PALM\",\"PAN\",\"PANTS\",\"PAPER\",\"PARACHUTE\",\"PARK\",\"PART\",\"PASS\",\"PASTE\",\"PENGUIN\",\"PHOENIX\",\"PIANO\",\"PIE\",\"PILOT\",\"PIN\",\"PIPE\",\"PIRATE\",\"PISTOL\",\"PIT\",\"PITCH\",\"PLANE\",\"PLASTIC\",\"PLATE\",\"PLATYPUS\",\"PLAY\",\"PLOT\",\"POINT\",\"POISON\",\"POLE\",\"POLICE\",\"POOL\",\"PORT\",\"POST\",\"POUND\",\"PRESS\",\"PRINCESS\",\"PUMPKIN\",\"PUPIL\",\"PYRAMID\",\"QUEEN\",\"RABBIT\",\"RACKET\",\"RAY\",\"REVOLUTION\",\"RING\",\"ROBIN\",\"ROBOT\",\"ROCK\",\"ROME\",\"ROOT\",\"ROSE\",\"ROULETTE\",\"ROUND\",\"ROW\",\"RULER\",\"SATELLITE\",\"SATURN\",\"SCALE\",\"SCHOOL\",\"SCIENTIST\",\"SCORPION\",\"SCREEN\",\"SCUBA DIVER\",\"SEAL\",\"SERVER\",\"SHADOW\",\"SHAKESPEARE\",\"SHARK\",\"SHIP\",\"SHOE\",\"SHOP\",\"SHOT\",\"SINK\",\"SKYSCRAPER\",\"SLIP\",\"SLUG\",\"SMUGGLER\",\"SNOW\",\"SNOWMAN\",\"SOCK\",\"SOLDIER\",\"SOUL\",\"SOUND\",\"SPACE\",\"SPELL\",\"SPIDER\",\"SPIKE\",\"SPINE\",\"SPOT\",\"SPRING\",\"SPY\",\"SQUARE\",\"STADIUM\",\"STAFF\",\"STAR\",\"STATE\",\"STICK\",\"STOCK\",\"STRAW\",\"STREAM\",\"STRIKE\",\"STRING\",\"SUB\",\"SUIT\",\"SUPERHERO\",\"SWING\",\"SWITCH\",\"TABLE\",\"TABLET\",\"TAG\",\"TAIL\",\"TAP\",\"TEACHER\",\"TELESCOPE\",\"TEMPLE\",\"THEATER\",\"THIEF\",\"THUMB\",\"TICK\",\"TIE\",\"TIME\",\"TOKYO\",\"TOOTH\",\"TORCH\",\"TOWER\",\"TRACK\",\"TRAIN\",\"TRIANGLE\",\"TRIP\",\"TRUNK\",\"TUBE\",\"TURKEY\",\"UNDERTAKER\",\"UNICORN\",\"VACUUM\",\"VAN\",\"VET\",\"WAKE\",\"WALL\",\"WAR\",\"WASHER\",\"WASHINGTON\",\"WATCH\",\"WATER\",\"WAVE\",\"WEB\",\"WELL\",\"WHALE\",\"WHIP\",\"WIND\",\"WITCH\",\"WORM\",\"YARD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a369ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import gensim\n",
    "import nltk\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca8c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e926058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    fasttext.util.download_model('es', if_exists='ignore')  # English\n",
    "else:\n",
    "    fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a78d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if language == \"spa\":\n",
    "    FAST_TEXT_MODEL = \"cc.es.300.bin\" # Model name in fasttext\n",
    "else:\n",
    "    FAST_TEXT_MODEL = \"cc.en.300.bin\"\n",
    "\n",
    "\n",
    "ft = fasttext.load_model(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b57af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_facebook_model(FAST_TEXT_MODEL)\n",
    "#model.wv.most_similar(positive=['red', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187f23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    words = spanish_words \n",
    "else: \n",
    "    words = english_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884caf7",
   "metadata": {},
   "source": [
    "# Medias entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b7db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    return model.wv.similarity(word1, word2)\n",
    "\n",
    "def get_synonyms(word1, lang = 'spa'):\n",
    "    all_synonyms = list(map(lambda x: x.lemma_names(lang), wn.synsets(word1, lang=lang)))\n",
    "    return list(set(itertools.chain(*all_synonyms)))\n",
    "\n",
    "def get_antonyms(word1, lang = 'spa'):\n",
    "    all_lemas = list(map(lambda x: x.lemmas(), wn.synsets(word1, lang=lang)))\n",
    "    all_antonyms_lemas = list(map(lambda x: x.antonyms(), list(itertools.chain(*all_lemas))))\n",
    "    all_antonyms = map(lambda x: x.synset().lemma_names(lang=lang), list(itertools.chain(*all_antonyms_lemas)))\n",
    "    return list(set(itertools.chain(*all_antonyms)))\n",
    "\n",
    "def get_synonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_synonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_synonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    synonyms = list(set(synonyms_word1).intersection(synonyms_word2))\n",
    "    if len(synonyms) !=0:\n",
    "        max_value = max(synonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_number_of_same_synonyms(word1, word2, lang = 'spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_number_of_same_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    return len(set(antonyms_word1).intersection(antonyms_word2))\n",
    "\n",
    "def get_number_synonyms_vs_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(antonyms_word2)) + len(set(antonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_antonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_antonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_antonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    antonyms = list(set(antonyms_word1).intersection(antonyms_word2))\n",
    "    if len(antonyms) != 0:\n",
    "        max_value = max(antonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_hypernyms_of_synsets(synsets):\n",
    "    hypernyms = list(map(lambda x: x.hypernyms(), synsets))\n",
    "    return list(set(itertools.chain(*hypernyms)))\n",
    "\n",
    "def get_path_similarity(synset1, synset2):\n",
    "    similarity = wn.path_similarity(synset1, synset2)\n",
    "    similarity = similarity if similarity else 0\n",
    "    return similarity\n",
    "\n",
    "def get_first_common_hypernym(word1, word2, lang = 'spa'):\n",
    "    temporal_hypernyms1 = get_hypernyms_of_synsets(wn.synsets(word1, lang=lang))\n",
    "    temporal_hypernyms2 = get_hypernyms_of_synsets(wn.synsets(word2, lang=lang))\n",
    "    hypernyms1 = list(set(temporal_hypernyms1))\n",
    "    hypernyms2 = list(set(temporal_hypernyms2))\n",
    "    while len(set(hypernyms1).intersection(hypernyms2))==0 and (len(temporal_hypernyms1)!=0 or len(temporal_hypernyms2)!=0):\n",
    "        hypernyms1 = list(set(hypernyms1 + temporal_hypernyms1))\n",
    "        hypernyms2 = list(set(hypernyms2 + temporal_hypernyms2))\n",
    "        temporal_hypernyms1 = get_hypernyms_of_synsets(temporal_hypernyms1)\n",
    "        temporal_hypernyms2 = get_hypernyms_of_synsets(temporal_hypernyms2)\n",
    "    if len(set(hypernyms1).intersection(hypernyms2))!=0:\n",
    "        hypernyms = list(set(hypernyms1).intersection(hypernyms2))\n",
    "        possible_hypernyms = list(map(lambda x: max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word1, lang=lang)))) + max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word2, lang=lang)))),hypernyms))\n",
    "        max_value = max(possible_hypernyms)\n",
    "        hypernym = hypernyms[possible_hypernyms.index(max_value)]\n",
    "        similarity_to_word1 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word1, lang=lang))))\n",
    "        similarity_to_word2 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word2, lang=lang))))\n",
    "    else:\n",
    "        hypernym = None\n",
    "        similarity_to_word1 = 0\n",
    "        similarity_to_word2 = 0\n",
    "    return hypernym, similarity_to_word1, similarity_to_word2\n",
    "    \n",
    "    \n",
    "def apply_all_metrics_to_words_df(df, model, word2, lang = 'spa'):\n",
    "    df['similarity'] = df.apply(lambda x: get_cosine_similarity(model, x['words'], word2), axis=1)\n",
    "    df['number_same_synonyms'] = df.apply(lambda x: get_number_of_same_synonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['number_same_antonyms'] = df.apply(lambda x: get_number_of_same_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['synonyms_vs_antonyms'] = df.apply(lambda x: get_number_synonyms_vs_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['max_similarity_synonym'] = df.apply(lambda x: get_max_synonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['max_similarity_antonym'] = df.apply(lambda x: get_max_antonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['distance_common_hypernym'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[1], axis=1)\n",
    "    df['distance_common_hypernym_from_word'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[2], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_definition(word, lang = 'spa'):\n",
    "    return list(map(lambda x: x.definition(),wn.synsets(word, lang= lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a6cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.es.300.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.download_model('es', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaabf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grado similaridad\n",
    "#Numero de sinonimos en común\n",
    "#Número de antónimos en común\n",
    "#Relación con los sinonimos\n",
    "#Relación con los antónimos\n",
    "#Familia semántica (Hiperonimos)\n",
    "#Número de palabras entre la pista y la evaluada(s)\n",
    "\n",
    "\n",
    "# Implementar distancia de la definiciones\n",
    "# Hacer clustering (jerarquico y k-means)\n",
    "# Implementar bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(words, columns = [\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf83b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb01bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_all_metrics_to_words_df(sample_data, model, 'dinero', lang=language)\n",
    "df.index = df.words\n",
    "df = df.drop(['words'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb799d",
   "metadata": {},
   "source": [
    "# Vectores como variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea26a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector(words):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = pd.DataFrame(words, columns = [\"words\"], index=words)\n",
    "    df_with_vectors[column_names] = df_with_vectors.apply(lambda x: list(ft.get_word_vector(x['words'])), axis=1, result_type='expand')\n",
    "    df_with_vectors = df_with_vectors.drop(['words'], axis=1)\n",
    "    return df_with_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cd5075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector_with_clue(words, clue):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = get_dataframe_with_coordinates_vector(words)\n",
    "    df_with_vectors_and_clue = pd.concat([df_with_vectors, pd.DataFrame([list(ft.get_word_vector(clue))], index=[clue], columns=column_names)])\n",
    "    return df_with_vectors_and_clue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea89d0e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b900428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cometa' 'ladrón' 'cámara' 'banco' 'alianza' 'pila' 'estadio' 'clase'\n",
      " 'barco' 'vacío' 'barra' 'misil' 'naranja' 'aceite' 'furgoneta' 'pavo'\n",
      " 'ninja' 'pekín' 'pastel' 'muerte' 'chuleta' 'pie' 'nudo' 'blanco' 'señal']\n"
     ]
    }
   ],
   "source": [
    "sample_words = np.random.choice(words, size=25, replace=False)\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(v1, v2):\n",
    "    return np.sqrt(np.sum(np.subtract(v1, v2)**2))\n",
    "\n",
    "def get_words_from_clue(sample_words, clue, number_words, model):\n",
    "    return list(filter(lambda element: element!= clue, list(get_dataframe_from_clue(sample_words, clue, number_words, model)[:number_words+1].index)))\n",
    "    \n",
    "\n",
    "def get_dataframe_from_clue(sample_words, clue, number_words, model):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector_with_clue(sample_words, clue)\n",
    "    kmeans = KMeans(n_clusters = 25 - number_words)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    clue_cluster = kmeans_response.cluster_centers_[df_for_clustering['cluster'][-1]]\n",
    "    distance_to_clue_cluster = list(map(lambda center: get_distance(center, clue_cluster), kmeans_response.cluster_centers_))\n",
    "    df_for_clustering['distance_to_clue_cluster'] = df_for_clustering.apply(lambda cluster: distance_to_clue_cluster[int(cluster['cluster'])], axis=1)\n",
    "    df_for_clustering['distance_to_clue'] = df_for_clustering.apply(lambda row: 1-model.wv.similarity(row.name, clue), axis=1)\n",
    "    return df_for_clustering[['cluster', 'distance_to_clue_cluster', 'distance_to_clue']].sort_values(by=['distance_to_clue_cluster', 'distance_to_clue'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "87a59c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_words(cluster, df_for_clustering, team):\n",
    "    return len(df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)])\n",
    "\n",
    "def get_distance_with_all_words(word, df_with_words):\n",
    "    df_with_words['distance_to_word'] = df_with_words.apply(lambda row: 1-model.wv.similarity(row.name, word), axis=1)\n",
    "    return np.sum(df_with_words['distance_to_word'])\n",
    "    \n",
    "def get_intracluster_distance(df):\n",
    "    if not df.empty:\n",
    "        df['row_number'] = np.arange(len(df))\n",
    "        df['sum_distance_to_words'] = df.apply(lambda row: get_distance_with_all_words(row.name,df[int(row['row_number']):]), axis=1)\n",
    "        return np.sum(df['sum_distance_to_words'])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_intracluster_distance_all(cluster, df_for_clustering):\n",
    "    df_with_cluster_words = df_for_clustering.loc[df_for_clustering['cluster']==cluster]\n",
    "    return get_intracluster_distance(df_with_cluster_words)\n",
    "\n",
    "def get_intracluster_distance_for_team(cluster, df_for_clustering, team):\n",
    "    df_with_team_cluster_words = df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)]\n",
    "    return get_intracluster_distance(df_with_team_cluster_words)\n",
    "\n",
    "def get_clusters_with_info(df, number_of_clusters):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector(df['words'])\n",
    "    kmeans = KMeans(n_clusters= number_of_clusters)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['team'] = df['team']\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    #df_for_clustering.groupby(level='cluster').agg({'team_words':, 'enemy_words':, 'white_words':, 'forbidden_word':, 'Intracluster_distance':, 'team_words_distance':, 'team_words_distance_to_center'::})\n",
    "    result_df = pd.DataFrame(range(0,number_of_clusters), columns = ['cluster'], index=range(0,number_of_clusters))\n",
    "    result_df['team_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    result_df['enemy_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'red'), axis=1)\n",
    "    result_df['white_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'white'), axis=1)\n",
    "    result_df['forbidden_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'black'), axis=1)\n",
    "    result_df['intracluster_distance'] = result_df.apply(lambda row: get_intracluster_distance_all(row['cluster'], df_for_clustering), axis=1)\n",
    "    result_df['intracluster_distance_team'] = result_df.apply(lambda row: get_intracluster_distance_for_team(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "83f7db7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>team_words</th>\n",
       "      <th>enemy_words</th>\n",
       "      <th>white_words</th>\n",
       "      <th>forbidden_words</th>\n",
       "      <th>intracluster_distance</th>\n",
       "      <th>intracluster_distance_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.400461e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.649804e+00</td>\n",
       "      <td>2.283602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.579791e+01</td>\n",
       "      <td>2.408164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  team_words  enemy_words  white_words  forbidden_words  \\\n",
       "0        0           1            0            1                1   \n",
       "1        1           3            1            1                0   \n",
       "2        2           0            0            1                0   \n",
       "3        3           1            0            0                0   \n",
       "4        4           0            0            1                0   \n",
       "5        5           3            4            3                0   \n",
       "6        6           0            1            0                0   \n",
       "7        7           0            1            0                0   \n",
       "8        8           0            1            0                0   \n",
       "9        9           0            1            0                0   \n",
       "\n",
       "   intracluster_distance  intracluster_distance_team  \n",
       "0           2.400461e+00                    0.000000  \n",
       "1           7.649804e+00                    2.283602  \n",
       "2           0.000000e+00                    0.000000  \n",
       "3           0.000000e+00                    0.000000  \n",
       "4           0.000000e+00                    0.000000  \n",
       "5           3.579791e+01                    2.408164  \n",
       "6           0.000000e+00                    0.000000  \n",
       "7           5.960464e-08                    0.000000  \n",
       "8           0.000000e+00                    0.000000  \n",
       "9           0.000000e+00                    0.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_words_teams = pd.DataFrame(sample_words, columns = [\"words\"], index=sample_words)\n",
    "dataframe_words_teams['team'] = ['blue']*8 + ['red']*9 + ['black'] + ['white']*7\n",
    "get_clusters_with_info(dataframe_words_teams, 7)\n",
    "get_clusters_with_info(dataframe_words_teams, 8)\n",
    "get_clusters_with_info(dataframe_words_teams, 9)\n",
    "get_clusters_with_info(dataframe_words_teams, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d23215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "clue='FOOTBALL'\n",
    "number_words = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "287b5fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STADIUM', 'HORSESHOE']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a209c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_dataframe_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a34cb347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>distance_to_clue_cluster</th>\n",
       "      <th>distance_to_clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOOTBALL</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanco</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>0.942250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naranja</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>0.959681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furgoneta</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>1.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastel</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>1.012201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estadio</th>\n",
       "      <td>12</td>\n",
       "      <td>1.099798</td>\n",
       "      <td>0.848451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alianza</th>\n",
       "      <td>22</td>\n",
       "      <td>1.152131</td>\n",
       "      <td>0.993659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chuleta</th>\n",
       "      <td>18</td>\n",
       "      <td>1.161818</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muerte</th>\n",
       "      <td>21</td>\n",
       "      <td>1.182141</td>\n",
       "      <td>1.021562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pekín</th>\n",
       "      <td>16</td>\n",
       "      <td>1.234856</td>\n",
       "      <td>0.897726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ladrón</th>\n",
       "      <td>15</td>\n",
       "      <td>1.281606</td>\n",
       "      <td>0.984432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cámara</th>\n",
       "      <td>14</td>\n",
       "      <td>1.285720</td>\n",
       "      <td>1.048124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cometa</th>\n",
       "      <td>8</td>\n",
       "      <td>1.314067</td>\n",
       "      <td>0.950417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aceite</th>\n",
       "      <td>20</td>\n",
       "      <td>1.332098</td>\n",
       "      <td>1.037552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clase</th>\n",
       "      <td>19</td>\n",
       "      <td>1.338715</td>\n",
       "      <td>1.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banco</th>\n",
       "      <td>7</td>\n",
       "      <td>1.365750</td>\n",
       "      <td>0.949857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>señal</th>\n",
       "      <td>13</td>\n",
       "      <td>1.397743</td>\n",
       "      <td>0.980324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barra</th>\n",
       "      <td>17</td>\n",
       "      <td>1.410490</td>\n",
       "      <td>0.912988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacío</th>\n",
       "      <td>2</td>\n",
       "      <td>1.424093</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barco</th>\n",
       "      <td>10</td>\n",
       "      <td>1.482593</td>\n",
       "      <td>1.038280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninja</th>\n",
       "      <td>4</td>\n",
       "      <td>1.500815</td>\n",
       "      <td>0.932044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misil</th>\n",
       "      <td>3</td>\n",
       "      <td>1.614788</td>\n",
       "      <td>0.921104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pila</th>\n",
       "      <td>9</td>\n",
       "      <td>1.648816</td>\n",
       "      <td>0.962193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>6</td>\n",
       "      <td>1.785408</td>\n",
       "      <td>0.958802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nudo</th>\n",
       "      <td>1</td>\n",
       "      <td>1.892498</td>\n",
       "      <td>0.992923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pie</th>\n",
       "      <td>5</td>\n",
       "      <td>2.161170</td>\n",
       "      <td>0.971958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster  distance_to_clue_cluster  distance_to_clue\n",
       "FOOTBALL        11                  0.000000          0.000000\n",
       "blanco           0                  1.020562          0.942250\n",
       "naranja          0                  1.020562          0.959681\n",
       "furgoneta        0                  1.020562          1.000852\n",
       "pastel           0                  1.020562          1.012201\n",
       "estadio         12                  1.099798          0.848451\n",
       "alianza         22                  1.152131          0.993659\n",
       "chuleta         18                  1.161818          0.970300\n",
       "muerte          21                  1.182141          1.021562\n",
       "pekín           16                  1.234856          0.897726\n",
       "ladrón          15                  1.281606          0.984432\n",
       "cámara          14                  1.285720          1.048124\n",
       "cometa           8                  1.314067          0.950417\n",
       "aceite          20                  1.332098          1.037552\n",
       "clase           19                  1.338715          1.006227\n",
       "banco            7                  1.365750          0.949857\n",
       "señal           13                  1.397743          0.980324\n",
       "barra           17                  1.410490          0.912988\n",
       "vacío            2                  1.424093          0.999906\n",
       "barco           10                  1.482593          1.038280\n",
       "ninja            4                  1.500815          0.932044\n",
       "misil            3                  1.614788          0.921104\n",
       "pila             9                  1.648816          0.962193\n",
       "pavo             6                  1.785408          0.958802\n",
       "nudo             1                  1.892498          0.992923\n",
       "pie              5                  2.161170          0.971958"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7805129f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9355464726686478"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intracluster_distance(0, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c75eb227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance_with_all_words('pastel',a[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "025a4ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9355464726686478"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.88876610994339 + 1.2487879991531372 + 0.7979923635721207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31528508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-codenames",
   "language": "python",
   "name": "py-codenames"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
