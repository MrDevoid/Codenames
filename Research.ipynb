{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0e57f",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a369ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import gensim\n",
    "import nltk\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470ce8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spa or eng\n",
    "SPANISH = 'spa'\n",
    "ENGLISH = 'eng'\n",
    "language = SPANISH\n",
    "\n",
    "spanish_words = [\"abogado\",\"aceite\",\"áfrica\",\"agente\",\"agua\",\"águila\",\"aguja\",\"agujero\",\"aire\",\"alemania\",\"algodón\",\"alianza\",\"alpes\",\"ambulancia\",\"américa\",\"ángel\",\"anillo\",\"antártida\",\"antorcha\",\"araña\",\"archivo\",\"arco\",\"argentina\",\"artículo\",\"as\",\"atlántida\",\"azteca\",\"baile\",\"bala\",\"ballena\",\"banco\",\"banda\",\"baño\",\"barco\",\"barra\",\"batería\",\"berlín\",\"bermudas\",\"bicho\",\"blanco\",\"bloque\",\"boca\",\"bola\",\"bolsa\",\"bomba\",\"bosque\",\"bota\",\"botella\",\"botón\",\"brazo\",\"bruja\",\"caballero\",\"caballo\",\"cabeza\",\"cabina\",\"cabo\",\"cactus\",\"cadena\",\"caja\",\"cama\",\"cámara\",\"cambio\",\"campana\",\"campo\",\"canal\",\"canguro\",\"canto\",\"caña\",\"capa\",\"capital\",\"caqui\",\"cara\",\"caravana\",\"carga\",\"carrera\",\"carro\",\"carta\",\"casco\",\"casino\",\"caza\",\"cementerio\",\"centauro\",\"centro\",\"cervantes\",\"checo\",\"chocolate\",\"choque\",\"chuleta\",\"científico\",\"cinta\",\"cinturón\",\"círculo\",\"clase\",\"coche\",\"cocinero\",\"coco\",\"código\",\"cola\",\"cólera\",\"columna\",\"cometa\",\"compás\",\"concierto\",\"conejo\",\"contrabandista\",\"copa\",\"corazón\",\"corneta\",\"corona\",\"corredor\",\"corriente\",\"corte\",\"cresta\",\"cromo\",\"cruz\",\"cuadro\",\"cuarto\",\"cubierta\",\"cubo\",\"cuchillo\",\"cuello\",\"cuerda\",\"cuerno\",\"cura\",\"dama\",\"delta\",\"destino\",\"día\",\"diamante\",\"diana\",\"diario\",\"diente\",\"dinosaurio\",\"disco\",\"don\",\"dragón\",\"duende\",\"egipto\",\"embajada\",\"emperador\",\"enano\",\"enfermedad\",\"enfermera\",\"enlace\",\"escorpión\",\"espacio\",\"espía\",\"estación\",\"estadio\",\"estado\",\"estrella\",\"estudio\",\"etiqueta\",\"europa\",\"extraterrestre\",\"falda\",\"fantasma\",\"faro\",\"ficha\",\"fiesta\",\"figura\",\"flauta\",\"flecha\",\"foso\",\"francia\",\"frente\",\"fuego\",\"fuente\",\"fuerza\",\"furgoneta\",\"gancho\",\"gato\",\"genio\",\"gigante\",\"golfo\",\"golondrina\",\"golpe\",\"goma\",\"góndola\",\"gota\",\"grado\",\"granada\",\"grano\",\"grecia\",\"grifo\",\"guante\",\"guardia\",\"guerra\",\"gusano\",\"helado\",\"helicóptero\",\"hielo\",\"hierba\",\"hoja\",\"hollywood\",\"horca\",\"hospital\",\"hotel\",\"iglesia\",\"imán\",\"india\",\"índice\",\"inglaterra\",\"italia\",\"jarra\",\"judía\",\"juicio\",\"kiwi\",\"ladrón\",\"lago ness\",\"láser\",\"látigo\",\"lengua\",\"león\",\"libra\",\"lima\",\"limusina\",\"línea\",\"lista\",\"llama\",\"llave\",\"lomo\",\"londres\",\"luna\",\"luz\",\"maestro\",\"magia\",\"malta\",\"mancha\",\"mando\",\"manga\",\"mango\",\"mano\",\"manzana\",\"mañana\",\"marca\",\"marcha\",\"marfil\",\"masa\",\"máscara\",\"mazo\",\"médico\",\"mercurio\",\"mesa\",\"metro\",\"méxico\",\"micro\",\"microscopi\",\"mielo\",\"millonario\",\"mina\",\"misil\",\"modelo\",\"módulo\",\"monitor\",\"mono\",\"mortero\",\"moscú\",\"motor\",\"muelle\",\"muerte\",\"muñeca\",\"muro\",\"naranja\",\"nave\",\"nieve\",\"nilo\",\"ninja\",\"noche\",\"nota\",\"nudo\",\"nueva york\",\"obra\",\"ojo\",\"ola\",\"olimpo\",\"ópera\",\"orden\",\"órgano\",\"ornitorrinco\",\"oro\",\"oso\",\"pala\",\"palma\",\"pantalla\",\"papel\",\"paracaídas\",\"pase\",\"paso\",\"pasta\",\"pastel\",\"pavo\",\"pekín\",\"película\",\"pelotón\",\"pendiente\",\"perro\",\"pez\",\"pico\",\"pie\",\"pieza\",\"pila\",\"piloto\",\"pincho\",\"pingüino\",\"pinta\",\"piña\",\"pirámide\",\"pirata\",\"pista\",\"pistola\",\"placa\",\"plano\",\"planta\",\"plátano\",\"playa\",\"plomo\",\"pluma\",\"policía\",\"polo\",\"portada\",\"portero\",\"potro\",\"prensa\",\"prima\",\"princesa\",\"puente\",\"puerto\",\"pulpo\",\"pulso\",\"punta\",\"punto\",\"radio\",\"rascacielos\",\"ratón\",\"rayo\",\"red\",\"regla\",\"reina\",\"reserva\",\"revolución\",\"rey\",\"robot\",\"rojo\",\"roma\",\"ronda\",\"rosa\",\"ruleta\",\"sable\",\"sáhara\",\"salsa\",\"satélite\",\"saturno\",\"señal\",\"serie\",\"serpiente\",\"sierra\",\"silla\",\"sirena\",\"sobre\",\"soldado\",\"submarinista\",\"suerte\",\"superhéroe\",\"tabla\",\"tableta\",\"taco\",\"tacto\",\"talón\",\"tanque\",\"tapa\",\"tarde\",\"teatro\",\"teclado\",\"telescopio\",\"testigo\",\"tiempo\",\"tienda\",\"tierra\",\"tokio\",\"topo\",\"torre\",\"trama\",\"tronco\",\"tubería\",\"tubo\",\"unicornio\",\"vacío\",\"vado\",\"vampiro\",\"vela\",\"veneno\",\"venus\",\"vestido\",\"vida\",\"vidrio\",\"viento\",\"yema\",\"zanahoria\",\"zapato\"]\n",
    "\n",
    "english_words = [\"AFRICA\",\"AGENT\",\"AIR\",\"ALIEN\",\"ALPS\",\"AMAZON\",\"AMBULANCE\",\"AMERICA\",\"ANGEL\",\"ANTARCTICA\",\"APPLE\",\"ARM\",\"ATLANTIS\",\"AUSTRALIA\",\"AZTEC\",\"BACK\",\"BALL\",\"BAND\",\"BANK\",\"BAR\",\"BARK\",\"BAT\",\"BATTERY\",\"BEACH\",\"BEAR\",\"BEAT\",\"BED\",\"BEIJING\",\"BELL\",\"BELT\",\"BERLIN\",\"BERMUDA\",\"BERRY\",\"BILL\",\"BLOCK\",\"BOARD\",\"BOLT\",\"BOMB\",\"BOND\",\"BOOM\",\"BOOT\",\"BOTTLE\",\"BOW\",\"BOX\",\"BRIDGE\",\"BRUSH\",\"BUCK\",\"BUFFALO\",\"BUG\",\"BUGLE\",\"BUTTON\",\"CALF\",\"CANADA\",\"CAP\",\"CAPITAL\",\"CAR\",\"CARD\",\"CARROT\",\"CASINO\",\"CAST\",\"CAT\",\"CELL\",\"CENTAUR\",\"CENTER\",\"CHAIR\",\"CHANGE\",\"CHARGE\",\"CHECK\",\"CHEST\",\"CHICK\",\"CHINA\",\"CHOCOLATE\",\"CHURCH\",\"CIRCLE\",\"CLIFF\",\"CLOAK\",\"CLUB\",\"CODE\",\"COLD\",\"COMIC\",\"COMPOUND\",\"CONCERT\",\"CONDUCTOR\",\"CONTRACT\",\"COOK\",\"COPPER\",\"COTTON\",\"COURT\",\"COVER\",\"CRANE\",\"CRASH\",\"CRICKET\",\"CROSS\",\"CROWN\",\"CYCLE\",\"CZECH\",\"DANCE\",\"DATE\",\"DAY\",\"DEATH\",\"DECK\",\"DEGREE\",\"DIAMOND\",\"DICE\",\"DINOSAUR\",\"DISEASE\",\"DOCTOR\",\"DOG\",\"DRAFT\",\"DRAGON\",\"DRESS\",\"DRILL\",\"DROP\",\"DUCK\",\"DWARF\",\"EAGLE\",\"EGYPT\",\"EMBASSY\",\"ENGINE\",\"ENGLAND\",\"EUROPE\",\"EYE\",\"FACE\",\"FAIR\",\"FALL\",\"FAN\",\"FENCE\",\"FIELD\",\"FIGHTER\",\"FIGURE\",\"FILE\",\"FILM\",\"FIRE\",\"FISH\",\"FLUTE\",\"FLY\",\"FOOT\",\"FORCE\",\"FOREST\",\"FORK\",\"FRANCE\",\"GAME\",\"GAS\",\"GENIUS\",\"GERMANY\",\"GHOST\",\"GIANT\",\"GLASS\",\"GLOVE\",\"GOLD\",\"GRACE\",\"GRASS\",\"GREECE\",\"GREEN\",\"GROUND\",\"HAM\",\"HAND\",\"HAWK\",\"HEAD\",\"HEART\",\"HELICOPTER\",\"HIMALAYAS\",\"HOLE\",\"HOLLYWOOD\",\"HONEY\",\"HOOD\",\"HOOK\",\"HORN\",\"HORSE\",\"HORSESHOE\",\"HOSPITAL\",\"HOTEL\",\"ICE\",\"ICE CREAM\",\"INDIA\",\"IRON\",\"IVORY\",\"JACK\",\"JAM\",\"JET\",\"JUPITER\",\"KANGAROO\",\"KETCHUP\",\"KEY\",\"KID\",\"KING\",\"KIWI\",\"KNIFE\",\"KNIGHT\",\"LAB\",\"LAP\",\"LASER\",\"LAWYER\",\"LEAD\",\"LEMON\",\"LEPRECHAUN\",\"LIFE\",\"LIGHT\",\"LIMOUSINE\",\"LINE\",\"LINK\",\"LION\",\"LITTER\",\"LOCH NESS\",\"LOCK\",\"LOG\",\"LONDON\",\"LUCK\",\"MAIL\",\"MAMMOTH\",\"MAPLE\",\"MARBLE\",\"MARCH\",\"MASS\",\"MATCH\",\"MERCURY\",\"MEXICO\",\"MICROSCOPE\",\"MILLIONAIRE\",\"MINE\",\"MINT\",\"MISSILE\",\"MODEL\",\"MOLE\",\"MOON\",\"MOSCOW\",\"MOUNT\",\"MOUSE\",\"MOUTH\",\"MUG\",\"NAIL\",\"NEEDLE\",\"NET\",\"NEW YORK\",\"NIGHT\",\"NINJA\",\"NOTE\",\"NOVEL\",\"NURSE\",\"NUT\",\"OCTOPUS\",\"OIL\",\"OLIVE\",\"OLYMPUS\",\"OPERA\",\"ORANGE\",\"ORGAN\",\"PALM\",\"PAN\",\"PANTS\",\"PAPER\",\"PARACHUTE\",\"PARK\",\"PART\",\"PASS\",\"PASTE\",\"PENGUIN\",\"PHOENIX\",\"PIANO\",\"PIE\",\"PILOT\",\"PIN\",\"PIPE\",\"PIRATE\",\"PISTOL\",\"PIT\",\"PITCH\",\"PLANE\",\"PLASTIC\",\"PLATE\",\"PLATYPUS\",\"PLAY\",\"PLOT\",\"POINT\",\"POISON\",\"POLE\",\"POLICE\",\"POOL\",\"PORT\",\"POST\",\"POUND\",\"PRESS\",\"PRINCESS\",\"PUMPKIN\",\"PUPIL\",\"PYRAMID\",\"QUEEN\",\"RABBIT\",\"RACKET\",\"RAY\",\"REVOLUTION\",\"RING\",\"ROBIN\",\"ROBOT\",\"ROCK\",\"ROME\",\"ROOT\",\"ROSE\",\"ROULETTE\",\"ROUND\",\"ROW\",\"RULER\",\"SATELLITE\",\"SATURN\",\"SCALE\",\"SCHOOL\",\"SCIENTIST\",\"SCORPION\",\"SCREEN\",\"SCUBA DIVER\",\"SEAL\",\"SERVER\",\"SHADOW\",\"SHAKESPEARE\",\"SHARK\",\"SHIP\",\"SHOE\",\"SHOP\",\"SHOT\",\"SINK\",\"SKYSCRAPER\",\"SLIP\",\"SLUG\",\"SMUGGLER\",\"SNOW\",\"SNOWMAN\",\"SOCK\",\"SOLDIER\",\"SOUL\",\"SOUND\",\"SPACE\",\"SPELL\",\"SPIDER\",\"SPIKE\",\"SPINE\",\"SPOT\",\"SPRING\",\"SPY\",\"SQUARE\",\"STADIUM\",\"STAFF\",\"STAR\",\"STATE\",\"STICK\",\"STOCK\",\"STRAW\",\"STREAM\",\"STRIKE\",\"STRING\",\"SUB\",\"SUIT\",\"SUPERHERO\",\"SWING\",\"SWITCH\",\"TABLE\",\"TABLET\",\"TAG\",\"TAIL\",\"TAP\",\"TEACHER\",\"TELESCOPE\",\"TEMPLE\",\"THEATER\",\"THIEF\",\"THUMB\",\"TICK\",\"TIE\",\"TIME\",\"TOKYO\",\"TOOTH\",\"TORCH\",\"TOWER\",\"TRACK\",\"TRAIN\",\"TRIANGLE\",\"TRIP\",\"TRUNK\",\"TUBE\",\"TURKEY\",\"UNDERTAKER\",\"UNICORN\",\"VACUUM\",\"VAN\",\"VET\",\"WAKE\",\"WALL\",\"WAR\",\"WASHER\",\"WASHINGTON\",\"WATCH\",\"WATER\",\"WAVE\",\"WEB\",\"WELL\",\"WHALE\",\"WHIP\",\"WIND\",\"WITCH\",\"WORM\",\"YARD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8840463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dda6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca8c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e926058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    fasttext.util.download_model('es', if_exists='ignore')  # English\n",
    "else:\n",
    "    fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a78d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if language == \"spa\":\n",
    "    FAST_TEXT_MODEL = \"cc.es.300.bin\" # Model name in fasttext\n",
    "else:\n",
    "    FAST_TEXT_MODEL = \"cc.en.300.bin\"\n",
    "\n",
    "\n",
    "ft = fasttext.load_model(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b57af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_facebook_model(FAST_TEXT_MODEL)\n",
    "#model.wv.most_similar(positive=['red', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187f23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == \"spa\":\n",
    "    words = spanish_words \n",
    "else: \n",
    "    words = english_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884caf7",
   "metadata": {},
   "source": [
    "# Medias entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b7db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    return model.wv.similarity(word1, word2)\n",
    "\n",
    "def get_synonyms(word1, lang = 'spa'):\n",
    "    all_synonyms = list(map(lambda x: x.lemma_names(lang), wn.synsets(word1, lang=lang)))\n",
    "    return list(set(itertools.chain(*all_synonyms)))\n",
    "\n",
    "def get_antonyms(word1, lang = 'spa'):\n",
    "    all_lemas = list(map(lambda x: x.lemmas(), wn.synsets(word1, lang=lang)))\n",
    "    all_antonyms_lemas = list(map(lambda x: x.antonyms(), list(itertools.chain(*all_lemas))))\n",
    "    all_antonyms = map(lambda x: x.synset().lemma_names(lang=lang), list(itertools.chain(*all_antonyms_lemas)))\n",
    "    return list(set(itertools.chain(*all_antonyms)))\n",
    "\n",
    "def get_synonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_synonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_synonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    synonyms = list(set(synonyms_word1).intersection(synonyms_word2))\n",
    "    if len(synonyms) !=0:\n",
    "        max_value = max(synonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_number_of_same_synonyms(word1, word2, lang = 'spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_number_of_same_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    return len(set(antonyms_word1).intersection(antonyms_word2))\n",
    "\n",
    "def get_number_synonyms_vs_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(antonyms_word2)) + len(set(antonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_antonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_antonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_antonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    antonyms = list(set(antonyms_word1).intersection(antonyms_word2))\n",
    "    if len(antonyms) != 0:\n",
    "        max_value = max(antonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_hypernyms_of_synsets(synsets):\n",
    "    hypernyms = list(map(lambda x: x.hypernyms(), synsets))\n",
    "    return list(set(itertools.chain(*hypernyms)))\n",
    "\n",
    "def get_path_similarity(synset1, synset2):\n",
    "    similarity = wn.path_similarity(synset1, synset2)\n",
    "    similarity = similarity if similarity else 0\n",
    "    return similarity\n",
    "\n",
    "def get_first_common_hypernym(word1, word2, lang = 'spa'):\n",
    "    temporal_hypernyms1 = get_hypernyms_of_synsets(wn.synsets(word1, lang=lang))\n",
    "    temporal_hypernyms2 = get_hypernyms_of_synsets(wn.synsets(word2, lang=lang))\n",
    "    hypernyms1 = list(set(temporal_hypernyms1))\n",
    "    hypernyms2 = list(set(temporal_hypernyms2))\n",
    "    while len(set(hypernyms1).intersection(hypernyms2))==0 and (len(temporal_hypernyms1)!=0 or len(temporal_hypernyms2)!=0):\n",
    "        hypernyms1 = list(set(hypernyms1 + temporal_hypernyms1))\n",
    "        hypernyms2 = list(set(hypernyms2 + temporal_hypernyms2))\n",
    "        temporal_hypernyms1 = get_hypernyms_of_synsets(temporal_hypernyms1)\n",
    "        temporal_hypernyms2 = get_hypernyms_of_synsets(temporal_hypernyms2)\n",
    "    if len(set(hypernyms1).intersection(hypernyms2))!=0:\n",
    "        hypernyms = list(set(hypernyms1).intersection(hypernyms2))\n",
    "        possible_hypernyms = list(map(lambda x: max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word1, lang=lang)))) + max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word2, lang=lang)))),hypernyms))\n",
    "        max_value = max(possible_hypernyms)\n",
    "        hypernym = hypernyms[possible_hypernyms.index(max_value)]\n",
    "        similarity_to_word1 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word1, lang=lang))))\n",
    "        similarity_to_word2 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word2, lang=lang))))\n",
    "    else:\n",
    "        hypernym = None\n",
    "        similarity_to_word1 = 0\n",
    "        similarity_to_word2 = 0\n",
    "    return hypernym, similarity_to_word1, similarity_to_word2\n",
    "    \n",
    "    \n",
    "def apply_all_metrics_to_words_df(df, model, word2, lang = 'spa'):\n",
    "    df['similarity'] = df.apply(lambda x: get_cosine_similarity(model, x['words'], word2), axis=1)\n",
    "    df['number_same_synonyms'] = df.apply(lambda x: get_number_of_same_synonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['number_same_antonyms'] = df.apply(lambda x: get_number_of_same_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['synonyms_vs_antonyms'] = df.apply(lambda x: get_number_synonyms_vs_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['max_similarity_synonym'] = df.apply(lambda x: get_max_synonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['max_similarity_antonym'] = df.apply(lambda x: get_max_antonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['distance_common_hypernym'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[1], axis=1)\n",
    "    df['distance_common_hypernym_from_word'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[2], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_definition(word, lang = 'spa'):\n",
    "    return list(map(lambda x: x.definition(),wn.synsets(word, lang= lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a6cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.es.300.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.download_model('es', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaabf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grado similaridad\n",
    "#Numero de sinonimos en común\n",
    "#Número de antónimos en común\n",
    "#Relación con los sinonimos\n",
    "#Relación con los antónimos\n",
    "#Familia semántica (Hiperonimos)\n",
    "#Número de palabras entre la pista y la evaluada(s)\n",
    "\n",
    "\n",
    "# Implementar distancia de la definiciones\n",
    "# Hacer clustering (jerarquico y k-means)\n",
    "# Implementar bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(words, columns = [\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf83b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb01bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_all_metrics_to_words_df(sample_data, model, 'dinero', lang=language)\n",
    "df.index = df.words\n",
    "df = df.drop(['words'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb799d",
   "metadata": {},
   "source": [
    "# Vectores como variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea26a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector(words):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = pd.DataFrame(words, columns = [\"words\"], index=words)\n",
    "    df_with_vectors[column_names] = df_with_vectors.apply(lambda x: list(ft.get_word_vector(x['words'])), axis=1, result_type='expand')\n",
    "    df_with_vectors = df_with_vectors.drop(['words'], axis=1)\n",
    "    return df_with_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd5075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector_with_clue(words, clue):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = get_dataframe_with_coordinates_vector(words)\n",
    "    df_with_vectors_and_clue = pd.concat([df_with_vectors, pd.DataFrame([list(ft.get_word_vector(clue))], index=[clue], columns=column_names)])\n",
    "    return df_with_vectors_and_clue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea89d0e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b900428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zapato' 'láser' 'aceite' 'columna' 'dama' 'reserva' 'enlace' 'copa'\n",
      " 'cresta' 'princesa' 'banco' 'fuego' 'europa' 'furgoneta' 'red' 'agua'\n",
      " 'emperador' 'as' 'vela' 'playa' 'prensa' 'sirena' 'canguro' 'marcha'\n",
      " 'suerte']\n"
     ]
    }
   ],
   "source": [
    "sample_words = np.random.choice(words, size=25, replace=False)\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "403728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(v1, v2):\n",
    "    return np.sqrt(np.sum(np.subtract(v1, v2)**2))\n",
    "\n",
    "def get_words_from_clue(sample_words, clue, number_words, model):\n",
    "    return list(filter(lambda element: element!= clue, list(get_dataframe_from_clue(sample_words, clue, number_words, model)[:number_words+1].index)))\n",
    "    \n",
    "\n",
    "def get_dataframe_from_clue(sample_words, clue, number_words, model):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector_with_clue(sample_words, clue)\n",
    "    kmeans = KMeans(n_clusters = 25 - number_words)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    clue_cluster = kmeans_response.cluster_centers_[df_for_clustering['cluster'][-1]]\n",
    "    distance_to_clue_cluster = list(map(lambda center: get_distance(center, clue_cluster), kmeans_response.cluster_centers_))\n",
    "    df_for_clustering['distance_to_clue_cluster'] = df_for_clustering.apply(lambda cluster: distance_to_clue_cluster[int(cluster['cluster'])], axis=1)\n",
    "    df_for_clustering['distance_to_clue'] = df_for_clustering.apply(lambda row: 1-model.wv.similarity(row.name, clue), axis=1)\n",
    "    return df_for_clustering[['cluster', 'distance_to_clue_cluster', 'distance_to_clue']].sort_values(by=['distance_to_clue_cluster', 'distance_to_clue'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a59c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_words(cluster, df_for_clustering, team):\n",
    "    return len(df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)])\n",
    "\n",
    "def get_distance_with_all_words(word, df_with_words):\n",
    "    df_with_words['distance_to_word'] = df_with_words.apply(lambda row: 1-model.wv.similarity(row.name, word), axis=1)\n",
    "    return np.sum(df_with_words['distance_to_word'])\n",
    "    \n",
    "def get_intracluster_distance(df):\n",
    "    if not df.empty:\n",
    "        df['row_number'] = np.arange(len(df))\n",
    "        df['sum_distance_to_words'] = df.apply(lambda row: get_distance_with_all_words(row.name,df[int(row['row_number']):]), axis=1)\n",
    "        return np.sum(df['sum_distance_to_words'])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_intracluster_distance_all(cluster, df_for_clustering):\n",
    "    df_with_cluster_words = df_for_clustering.loc[df_for_clustering['cluster']==cluster]\n",
    "    return get_intracluster_distance(df_with_cluster_words)\n",
    "\n",
    "def get_intracluster_distance_for_team(cluster, df_for_clustering, team):\n",
    "    df_with_team_cluster_words = df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)]\n",
    "    return get_intracluster_distance(df_with_team_cluster_words)\n",
    "\n",
    "def get_clusters_with_info(df, number_of_clusters):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector(df['words'])\n",
    "    kmeans = KMeans(n_clusters= number_of_clusters)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['team'] = df['team']\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    #df_for_clustering.groupby(level='cluster').agg({'team_words':, 'enemy_words':, 'white_words':, 'forbidden_word':, 'Intracluster_distance':, 'team_words_distance':, 'team_words_distance_to_center'::})\n",
    "    result_df = pd.DataFrame(range(0,number_of_clusters), columns = ['cluster'], index=range(0,number_of_clusters))\n",
    "    result_df['cluster_info'] = kmeans_response\n",
    "    result_df['number_of_clusters'] = number_of_clusters\n",
    "    result_df['team_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    result_df['enemy_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'red'), axis=1)\n",
    "    result_df['white_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'white'), axis=1)\n",
    "    result_df['forbidden_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'black'), axis=1)\n",
    "    result_df['intracluster_distance'] = result_df.apply(lambda row: get_intracluster_distance_all(row['cluster'], df_for_clustering), axis=1)\n",
    "    result_df['intracluster_distance_team'] = result_df.apply(lambda row: get_intracluster_distance_for_team(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83f7db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "dataframe_words_teams = pd.DataFrame(sample_words, columns = [\"words\"], index=sample_words)\n",
    "dataframe_words_teams['team'] = ['blue']*8 + ['red']*9 + ['black'] + ['white']*7\n",
    "\n",
    "final_df = get_clusters_with_info(dataframe_words_teams, 3)\n",
    "for number_clusters in range(4, 26):\n",
    "    final_df = pd.concat([final_df, get_clusters_with_info(dataframe_words_teams, number_clusters)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fbc3cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5905613e-02, -1.4281126e-02,  4.4774469e-02, -1.9252611e-03,\n",
       "       -3.2310651e-03, -4.6899058e-03, -7.4606519e-03, -1.2266046e-02,\n",
       "        9.9078938e-03, -3.8182337e-02,  6.4778426e-03, -9.4321212e-03,\n",
       "        3.8914275e-03,  2.2007279e-02, -3.3166192e-02,  4.5093182e-03,\n",
       "       -2.3443794e-02, -4.2392466e-02, -7.8416392e-03,  7.3209107e-03,\n",
       "       -3.6338210e-02, -4.7269138e-03,  1.8466534e-03,  3.4093495e-02,\n",
       "       -1.2711161e-02, -2.6853560e-02, -1.9006929e-03, -1.9788761e-03,\n",
       "       -1.8632915e-02,  3.0937489e-02, -2.5084948e-02, -2.4752785e-02,\n",
       "       -2.1433905e-03, -2.2127002e-02, -5.3075901e-03,  7.4584167e-03,\n",
       "       -9.0664783e-03, -2.4611987e-02, -4.1432679e-03,  3.8977839e-02,\n",
       "       -4.2860918e-02,  1.8057050e-02,  1.2178349e-02,  4.1549653e-04,\n",
       "       -2.6465561e-02,  2.3855040e-02,  2.1144325e-02,  9.1029722e-03,\n",
       "        9.2871953e-03, -4.3379562e-03,  9.9904044e-03,  3.2946378e-02,\n",
       "        5.1142637e-02,  1.6422743e-02,  1.1524317e-03,  5.8409754e-02,\n",
       "       -1.5209870e-02, -2.4667710e-02, -6.5409523e-03, -8.5104434e-03,\n",
       "       -1.0388619e-02,  3.9263004e-03, -2.6670819e-02, -2.1736618e-02,\n",
       "        3.6000926e-03, -3.8358010e-02,  1.6920956e-02,  3.4591101e-02,\n",
       "       -1.4055641e-02, -3.1882633e-02, -2.8795760e-02,  2.5750929e-02,\n",
       "        2.7312525e-03,  8.4467633e-03, -2.7487893e-04,  1.3485536e-02,\n",
       "        3.5308480e-02,  3.5783714e-03,  1.7237859e-02, -5.9970380e-03,\n",
       "       -1.4247373e-03,  1.6203649e-02, -4.0919543e-03,  7.9331733e-03,\n",
       "        1.4942139e-02,  1.3722342e-02,  1.0445742e-03, -2.0308273e-02,\n",
       "       -1.1434555e-03, -3.2207679e-02, -7.7555105e-03, -1.8944307e-03,\n",
       "       -3.8621005e-02,  1.9745527e-02,  1.8185161e-02,  1.0498474e-02,\n",
       "        4.6950597e-03, -8.4997471e-03,  7.4258917e-03,  2.1007936e-03,\n",
       "        2.3026234e-02,  2.2955416e-03, -3.6249172e-02, -2.6381370e-02,\n",
       "       -2.1398179e-03, -1.6930837e-02, -1.2371200e-02,  2.9640941e-02,\n",
       "        1.1393901e-02,  4.8425417e-02, -2.4283238e-02, -2.0012041e-03,\n",
       "        2.5009817e-02,  1.9150862e-02, -7.5348059e-04,  7.9103550e-03,\n",
       "        4.5872694e-03, -2.4123188e-02,  1.9121185e-02,  4.6788910e-03,\n",
       "       -3.1482531e-03, -3.3988491e-02,  1.2754556e-03,  6.8193208e-04,\n",
       "        1.5688525e-03,  1.6118800e-02, -1.9630330e-02,  2.2704167e-02,\n",
       "       -4.9818914e-02,  1.8558361e-02, -4.3053865e-02,  8.5699446e-02,\n",
       "        5.5282498e-03,  7.6719314e-02,  1.2864354e-02,  2.0221373e-02,\n",
       "        2.6985645e-02,  1.2828754e-02,  1.7439082e-02,  1.8628640e-03,\n",
       "       -5.4392698e-03, -1.4311600e-02, -2.0657489e-03, -7.1610902e-03,\n",
       "        1.9336031e-03,  8.8845175e-03,  1.9406756e-02,  1.0322549e-02,\n",
       "       -1.1876323e-02, -2.4730114e-03, -9.5120929e-03,  2.7431503e-02,\n",
       "        4.4555441e-03, -1.4984869e-02,  1.5231520e-02,  1.3804488e-03,\n",
       "       -7.4620373e-03, -1.0967536e-02, -3.6776531e-05,  2.4903342e-03,\n",
       "        3.3142161e-02,  1.3837116e-02, -2.5247617e-03, -1.3181200e-02,\n",
       "       -5.5511156e-03,  6.2399870e-03, -3.1660516e-02,  8.9778798e-03,\n",
       "       -6.9773467e-03,  1.8537756e-02,  8.1597436e-03, -1.1132916e-02,\n",
       "       -5.7600695e-03,  1.3455504e-02,  3.5078809e-02,  6.0178582e-03,\n",
       "        1.0650847e-02,  1.0243596e-02,  1.6526431e-02, -9.6472669e-03,\n",
       "        7.5045206e-02,  4.4526577e-02,  3.6325164e-02,  8.3850306e-03,\n",
       "       -1.0642659e-02, -2.6325658e-02, -1.5269032e-02, -1.6168775e-02,\n",
       "       -1.0895597e-02,  5.1234523e-04, -9.1993790e-03,  1.6468721e-02,\n",
       "       -5.5127693e-03,  1.4105128e-02, -2.6049634e-02,  3.8166106e-02,\n",
       "        1.7993473e-02, -2.8215203e-02, -3.0395836e-02,  1.1374310e-01,\n",
       "       -6.8548173e-02,  1.1292705e-02, -6.3766330e-02, -2.4129771e-02,\n",
       "        3.2685176e-03,  6.7734689e-02, -4.8076645e-02, -1.2606080e-01,\n",
       "       -9.2270464e-02, -2.9667320e-02, -5.1150888e-02,  8.1963623e-03,\n",
       "       -3.4018360e-02,  1.1299879e-03,  3.2139186e-02,  4.9654166e-03,\n",
       "       -3.5042267e-02,  2.8296459e-02,  1.8142875e-02, -6.3174991e-03,\n",
       "        3.6032192e-02,  1.1190814e-02, -8.4776403e-03,  9.8743467e-03,\n",
       "        8.6553441e-03,  3.0332480e-02, -3.3647111e-03,  2.5522318e-02,\n",
       "        7.5288313e-03, -1.1441847e-02, -1.7123686e-02, -5.1025301e-03,\n",
       "       -9.8340530e-03, -1.4914705e-02, -1.7354323e-02, -1.6613822e-02,\n",
       "       -6.8806098e-03,  2.2686023e-02, -2.1623932e-03, -2.6687015e-02,\n",
       "       -1.7409462e-02,  2.3233021e-02, -2.2683904e-02, -2.4612850e-02,\n",
       "       -3.6066435e-02, -2.0613695e-02,  1.1267262e-02,  9.0844966e-02,\n",
       "        1.0597996e-02, -5.4444600e-02,  5.7716656e-02,  3.0709818e-02,\n",
       "        8.6792864e-02, -3.3146173e-02, -5.1056454e-04, -3.1886231e-02,\n",
       "        3.2514025e-02,  1.5503327e-02,  1.4067898e-02,  2.2058913e-02,\n",
       "       -9.9397609e-03,  7.5405524e-03, -2.1429352e-02, -8.5041098e-02,\n",
       "       -4.8938755e-02, -2.4178140e-02,  2.1099204e-02, -4.1101594e-04,\n",
       "        3.9112754e-03, -2.4963459e-03,  1.6855050e-02,  9.2968727e-03,\n",
       "        2.2854088e-03, -1.6768191e-02,  2.3978554e-02, -7.8778580e-02,\n",
       "        1.5595618e-02, -1.9331291e-02,  7.7116829e-03, -1.3186974e-02,\n",
       "       -1.9839501e-02,  1.6015187e-02, -9.8515749e-03, -2.5014598e-02,\n",
       "       -3.8895436e-02,  5.7242857e-04,  4.0822282e-02, -1.8069353e-02,\n",
       "        2.2460407e-02, -3.0956946e-02, -3.3215497e-02, -6.9560304e-02,\n",
       "       -3.0392919e-02,  1.1686965e-02,  1.5717171e-03,  8.0708517e-03,\n",
       "        1.2583464e-02, -3.9736610e-03,  8.2937544e-03, -2.0039910e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.loc[0]['cluster_info'].cluster_centers_[final_df.loc[0]['cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d23215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "clue='FOOTBALL'\n",
    "number_words = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "287b5fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STADIUM', 'HORSESHOE']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a209c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_dataframe_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a34cb347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>distance_to_clue_cluster</th>\n",
       "      <th>distance_to_clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOOTBALL</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blanco</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>0.942250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naranja</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>0.959681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>furgoneta</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>1.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastel</th>\n",
       "      <td>0</td>\n",
       "      <td>1.020562</td>\n",
       "      <td>1.012201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estadio</th>\n",
       "      <td>12</td>\n",
       "      <td>1.099798</td>\n",
       "      <td>0.848451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alianza</th>\n",
       "      <td>22</td>\n",
       "      <td>1.152131</td>\n",
       "      <td>0.993659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chuleta</th>\n",
       "      <td>18</td>\n",
       "      <td>1.161818</td>\n",
       "      <td>0.970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muerte</th>\n",
       "      <td>21</td>\n",
       "      <td>1.182141</td>\n",
       "      <td>1.021562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pekín</th>\n",
       "      <td>16</td>\n",
       "      <td>1.234856</td>\n",
       "      <td>0.897726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ladrón</th>\n",
       "      <td>15</td>\n",
       "      <td>1.281606</td>\n",
       "      <td>0.984432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cámara</th>\n",
       "      <td>14</td>\n",
       "      <td>1.285720</td>\n",
       "      <td>1.048124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cometa</th>\n",
       "      <td>8</td>\n",
       "      <td>1.314067</td>\n",
       "      <td>0.950417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aceite</th>\n",
       "      <td>20</td>\n",
       "      <td>1.332098</td>\n",
       "      <td>1.037552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clase</th>\n",
       "      <td>19</td>\n",
       "      <td>1.338715</td>\n",
       "      <td>1.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banco</th>\n",
       "      <td>7</td>\n",
       "      <td>1.365750</td>\n",
       "      <td>0.949857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>señal</th>\n",
       "      <td>13</td>\n",
       "      <td>1.397743</td>\n",
       "      <td>0.980324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barra</th>\n",
       "      <td>17</td>\n",
       "      <td>1.410490</td>\n",
       "      <td>0.912988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacío</th>\n",
       "      <td>2</td>\n",
       "      <td>1.424093</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barco</th>\n",
       "      <td>10</td>\n",
       "      <td>1.482593</td>\n",
       "      <td>1.038280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninja</th>\n",
       "      <td>4</td>\n",
       "      <td>1.500815</td>\n",
       "      <td>0.932044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misil</th>\n",
       "      <td>3</td>\n",
       "      <td>1.614788</td>\n",
       "      <td>0.921104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pila</th>\n",
       "      <td>9</td>\n",
       "      <td>1.648816</td>\n",
       "      <td>0.962193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pavo</th>\n",
       "      <td>6</td>\n",
       "      <td>1.785408</td>\n",
       "      <td>0.958802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nudo</th>\n",
       "      <td>1</td>\n",
       "      <td>1.892498</td>\n",
       "      <td>0.992923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pie</th>\n",
       "      <td>5</td>\n",
       "      <td>2.161170</td>\n",
       "      <td>0.971958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster  distance_to_clue_cluster  distance_to_clue\n",
       "FOOTBALL        11                  0.000000          0.000000\n",
       "blanco           0                  1.020562          0.942250\n",
       "naranja          0                  1.020562          0.959681\n",
       "furgoneta        0                  1.020562          1.000852\n",
       "pastel           0                  1.020562          1.012201\n",
       "estadio         12                  1.099798          0.848451\n",
       "alianza         22                  1.152131          0.993659\n",
       "chuleta         18                  1.161818          0.970300\n",
       "muerte          21                  1.182141          1.021562\n",
       "pekín           16                  1.234856          0.897726\n",
       "ladrón          15                  1.281606          0.984432\n",
       "cámara          14                  1.285720          1.048124\n",
       "cometa           8                  1.314067          0.950417\n",
       "aceite          20                  1.332098          1.037552\n",
       "clase           19                  1.338715          1.006227\n",
       "banco            7                  1.365750          0.949857\n",
       "señal           13                  1.397743          0.980324\n",
       "barra           17                  1.410490          0.912988\n",
       "vacío            2                  1.424093          0.999906\n",
       "barco           10                  1.482593          1.038280\n",
       "ninja            4                  1.500815          0.932044\n",
       "misil            3                  1.614788          0.921104\n",
       "pila             9                  1.648816          0.962193\n",
       "pavo             6                  1.785408          0.958802\n",
       "nudo             1                  1.892498          0.992923\n",
       "pie              5                  2.161170          0.971958"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7805129f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9355464726686478"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intracluster_distance(0, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c75eb227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distance_with_all_words('pastel',a[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "025a4ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9355464726686478"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.88876610994339 + 1.2487879991531372 + 0.7979923635721207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31528508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-codenames",
   "language": "python",
   "name": "py-codenames"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
