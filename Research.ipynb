{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a0e57f",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a369ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import gensim\n",
    "import nltk\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import FastText, Word2Vec\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470ce8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "#spa or eng\n",
    "SPANISH = 'spa'\n",
    "ENGLISH = 'eng'\n",
    "language = SPANISH\n",
    "\n",
    "spanish_words = [\"abogado\",\"aceite\",\"áfrica\",\"agente\",\"agua\",\"águila\",\"aguja\",\"agujero\",\"aire\",\"alemania\",\"algodón\",\"alianza\",\"alpes\",\"ambulancia\",\"américa\",\"ángel\",\"anillo\",\"antártida\",\"antorcha\",\"araña\",\"archivo\",\"arco\",\"argentina\",\"artículo\",\"as\",\"atlántida\",\"azteca\",\"baile\",\"bala\",\"ballena\",\"banco\",\"banda\",\"baño\",\"barco\",\"barra\",\"batería\",\"berlín\",\"bermudas\",\"bicho\",\"blanco\",\"bloque\",\"boca\",\"bola\",\"bolsa\",\"bomba\",\"bosque\",\"bota\",\"botella\",\"botón\",\"brazo\",\"bruja\",\"caballero\",\"caballo\",\"cabeza\",\"cabina\",\"cabo\",\"cactus\",\"cadena\",\"caja\",\"cama\",\"cámara\",\"cambio\",\"campana\",\"campo\",\"canal\",\"canguro\",\"canto\",\"caña\",\"capa\",\"capital\",\"caqui\",\"cara\",\"caravana\",\"carga\",\"carrera\",\"carro\",\"carta\",\"casco\",\"casino\",\"caza\",\"cementerio\",\"centauro\",\"centro\",\"cervantes\",\"checo\",\"chocolate\",\"choque\",\"chuleta\",\"científico\",\"cinta\",\"cinturón\",\"círculo\",\"clase\",\"coche\",\"cocinero\",\"coco\",\"código\",\"cola\",\"cólera\",\"columna\",\"cometa\",\"compás\",\"concierto\",\"conejo\",\"contrabandista\",\"copa\",\"corazón\",\"corneta\",\"corona\",\"corredor\",\"corriente\",\"corte\",\"cresta\",\"cromo\",\"cruz\",\"cuadro\",\"cuarto\",\"cubierta\",\"cubo\",\"cuchillo\",\"cuello\",\"cuerda\",\"cuerno\",\"cura\",\"dama\",\"delta\",\"destino\",\"día\",\"diamante\",\"diana\",\"diario\",\"diente\",\"dinosaurio\",\"disco\",\"don\",\"dragón\",\"duende\",\"egipto\",\"embajada\",\"emperador\",\"enano\",\"enfermedad\",\"enfermera\",\"enlace\",\"escorpión\",\"espacio\",\"espía\",\"estación\",\"estadio\",\"estado\",\"estrella\",\"estudio\",\"etiqueta\",\"europa\",\"extraterrestre\",\"falda\",\"fantasma\",\"faro\",\"ficha\",\"fiesta\",\"figura\",\"flauta\",\"flecha\",\"foso\",\"francia\",\"frente\",\"fuego\",\"fuente\",\"fuerza\",\"furgoneta\",\"gancho\",\"gato\",\"genio\",\"gigante\",\"golfo\",\"golondrina\",\"golpe\",\"goma\",\"góndola\",\"gota\",\"grado\",\"granada\",\"grano\",\"grecia\",\"grifo\",\"guante\",\"guardia\",\"guerra\",\"gusano\",\"helado\",\"helicóptero\",\"hielo\",\"hierba\",\"hoja\",\"hollywood\",\"horca\",\"hospital\",\"hotel\",\"iglesia\",\"imán\",\"india\",\"índice\",\"inglaterra\",\"italia\",\"jarra\",\"judía\",\"juicio\",\"kiwi\",\"ladrón\",\"lago ness\",\"láser\",\"látigo\",\"lengua\",\"león\",\"libra\",\"lima\",\"limusina\",\"línea\",\"lista\",\"llama\",\"llave\",\"lomo\",\"londres\",\"luna\",\"luz\",\"maestro\",\"magia\",\"malta\",\"mancha\",\"mando\",\"manga\",\"mango\",\"mano\",\"manzana\",\"mañana\",\"marca\",\"marcha\",\"marfil\",\"masa\",\"máscara\",\"mazo\",\"médico\",\"mercurio\",\"mesa\",\"metro\",\"méxico\",\"micro\",\"microscopi\",\"mielo\",\"millonario\",\"mina\",\"misil\",\"modelo\",\"módulo\",\"monitor\",\"mono\",\"mortero\",\"moscú\",\"motor\",\"muelle\",\"muerte\",\"muñeca\",\"muro\",\"naranja\",\"nave\",\"nieve\",\"nilo\",\"ninja\",\"noche\",\"nota\",\"nudo\",\"nueva york\",\"obra\",\"ojo\",\"ola\",\"olimpo\",\"ópera\",\"orden\",\"órgano\",\"ornitorrinco\",\"oro\",\"oso\",\"pala\",\"palma\",\"pantalla\",\"papel\",\"paracaídas\",\"pase\",\"paso\",\"pasta\",\"pastel\",\"pavo\",\"pekín\",\"película\",\"pelotón\",\"pendiente\",\"perro\",\"pez\",\"pico\",\"pie\",\"pieza\",\"pila\",\"piloto\",\"pincho\",\"pingüino\",\"pinta\",\"piña\",\"pirámide\",\"pirata\",\"pista\",\"pistola\",\"placa\",\"plano\",\"planta\",\"plátano\",\"playa\",\"plomo\",\"pluma\",\"policía\",\"polo\",\"portada\",\"portero\",\"potro\",\"prensa\",\"prima\",\"princesa\",\"puente\",\"puerto\",\"pulpo\",\"pulso\",\"punta\",\"punto\",\"radio\",\"rascacielos\",\"ratón\",\"rayo\",\"red\",\"regla\",\"reina\",\"reserva\",\"revolución\",\"rey\",\"robot\",\"rojo\",\"roma\",\"ronda\",\"rosa\",\"ruleta\",\"sable\",\"sáhara\",\"salsa\",\"satélite\",\"saturno\",\"señal\",\"serie\",\"serpiente\",\"sierra\",\"silla\",\"sirena\",\"sobre\",\"soldado\",\"submarinista\",\"suerte\",\"superhéroe\",\"tabla\",\"tableta\",\"taco\",\"tacto\",\"talón\",\"tanque\",\"tapa\",\"tarde\",\"teatro\",\"teclado\",\"telescopio\",\"testigo\",\"tiempo\",\"tienda\",\"tierra\",\"tokio\",\"topo\",\"torre\",\"trama\",\"tronco\",\"tubería\",\"tubo\",\"unicornio\",\"vacío\",\"vado\",\"vampiro\",\"vela\",\"veneno\",\"venus\",\"vestido\",\"vida\",\"vidrio\",\"viento\",\"yema\",\"zanahoria\",\"zapato\"]\n",
    "\n",
    "english_words = [\"AFRICA\",\"AGENT\",\"AIR\",\"ALIEN\",\"ALPS\",\"AMAZON\",\"AMBULANCE\",\"AMERICA\",\"ANGEL\",\"ANTARCTICA\",\"APPLE\",\"ARM\",\"ATLANTIS\",\"AUSTRALIA\",\"AZTEC\",\"BACK\",\"BALL\",\"BAND\",\"BANK\",\"BAR\",\"BARK\",\"BAT\",\"BATTERY\",\"BEACH\",\"BEAR\",\"BEAT\",\"BED\",\"BEIJING\",\"BELL\",\"BELT\",\"BERLIN\",\"BERMUDA\",\"BERRY\",\"BILL\",\"BLOCK\",\"BOARD\",\"BOLT\",\"BOMB\",\"BOND\",\"BOOM\",\"BOOT\",\"BOTTLE\",\"BOW\",\"BOX\",\"BRIDGE\",\"BRUSH\",\"BUCK\",\"BUFFALO\",\"BUG\",\"BUGLE\",\"BUTTON\",\"CALF\",\"CANADA\",\"CAP\",\"CAPITAL\",\"CAR\",\"CARD\",\"CARROT\",\"CASINO\",\"CAST\",\"CAT\",\"CELL\",\"CENTAUR\",\"CENTER\",\"CHAIR\",\"CHANGE\",\"CHARGE\",\"CHECK\",\"CHEST\",\"CHICK\",\"CHINA\",\"CHOCOLATE\",\"CHURCH\",\"CIRCLE\",\"CLIFF\",\"CLOAK\",\"CLUB\",\"CODE\",\"COLD\",\"COMIC\",\"COMPOUND\",\"CONCERT\",\"CONDUCTOR\",\"CONTRACT\",\"COOK\",\"COPPER\",\"COTTON\",\"COURT\",\"COVER\",\"CRANE\",\"CRASH\",\"CRICKET\",\"CROSS\",\"CROWN\",\"CYCLE\",\"CZECH\",\"DANCE\",\"DATE\",\"DAY\",\"DEATH\",\"DECK\",\"DEGREE\",\"DIAMOND\",\"DICE\",\"DINOSAUR\",\"DISEASE\",\"DOCTOR\",\"DOG\",\"DRAFT\",\"DRAGON\",\"DRESS\",\"DRILL\",\"DROP\",\"DUCK\",\"DWARF\",\"EAGLE\",\"EGYPT\",\"EMBASSY\",\"ENGINE\",\"ENGLAND\",\"EUROPE\",\"EYE\",\"FACE\",\"FAIR\",\"FALL\",\"FAN\",\"FENCE\",\"FIELD\",\"FIGHTER\",\"FIGURE\",\"FILE\",\"FILM\",\"FIRE\",\"FISH\",\"FLUTE\",\"FLY\",\"FOOT\",\"FORCE\",\"FOREST\",\"FORK\",\"FRANCE\",\"GAME\",\"GAS\",\"GENIUS\",\"GERMANY\",\"GHOST\",\"GIANT\",\"GLASS\",\"GLOVE\",\"GOLD\",\"GRACE\",\"GRASS\",\"GREECE\",\"GREEN\",\"GROUND\",\"HAM\",\"HAND\",\"HAWK\",\"HEAD\",\"HEART\",\"HELICOPTER\",\"HIMALAYAS\",\"HOLE\",\"HOLLYWOOD\",\"HONEY\",\"HOOD\",\"HOOK\",\"HORN\",\"HORSE\",\"HORSESHOE\",\"HOSPITAL\",\"HOTEL\",\"ICE\",\"ICE CREAM\",\"INDIA\",\"IRON\",\"IVORY\",\"JACK\",\"JAM\",\"JET\",\"JUPITER\",\"KANGAROO\",\"KETCHUP\",\"KEY\",\"KID\",\"KING\",\"KIWI\",\"KNIFE\",\"KNIGHT\",\"LAB\",\"LAP\",\"LASER\",\"LAWYER\",\"LEAD\",\"LEMON\",\"LEPRECHAUN\",\"LIFE\",\"LIGHT\",\"LIMOUSINE\",\"LINE\",\"LINK\",\"LION\",\"LITTER\",\"LOCH NESS\",\"LOCK\",\"LOG\",\"LONDON\",\"LUCK\",\"MAIL\",\"MAMMOTH\",\"MAPLE\",\"MARBLE\",\"MARCH\",\"MASS\",\"MATCH\",\"MERCURY\",\"MEXICO\",\"MICROSCOPE\",\"MILLIONAIRE\",\"MINE\",\"MINT\",\"MISSILE\",\"MODEL\",\"MOLE\",\"MOON\",\"MOSCOW\",\"MOUNT\",\"MOUSE\",\"MOUTH\",\"MUG\",\"NAIL\",\"NEEDLE\",\"NET\",\"NEW YORK\",\"NIGHT\",\"NINJA\",\"NOTE\",\"NOVEL\",\"NURSE\",\"NUT\",\"OCTOPUS\",\"OIL\",\"OLIVE\",\"OLYMPUS\",\"OPERA\",\"ORANGE\",\"ORGAN\",\"PALM\",\"PAN\",\"PANTS\",\"PAPER\",\"PARACHUTE\",\"PARK\",\"PART\",\"PASS\",\"PASTE\",\"PENGUIN\",\"PHOENIX\",\"PIANO\",\"PIE\",\"PILOT\",\"PIN\",\"PIPE\",\"PIRATE\",\"PISTOL\",\"PIT\",\"PITCH\",\"PLANE\",\"PLASTIC\",\"PLATE\",\"PLATYPUS\",\"PLAY\",\"PLOT\",\"POINT\",\"POISON\",\"POLE\",\"POLICE\",\"POOL\",\"PORT\",\"POST\",\"POUND\",\"PRESS\",\"PRINCESS\",\"PUMPKIN\",\"PUPIL\",\"PYRAMID\",\"QUEEN\",\"RABBIT\",\"RACKET\",\"RAY\",\"REVOLUTION\",\"RING\",\"ROBIN\",\"ROBOT\",\"ROCK\",\"ROME\",\"ROOT\",\"ROSE\",\"ROULETTE\",\"ROUND\",\"ROW\",\"RULER\",\"SATELLITE\",\"SATURN\",\"SCALE\",\"SCHOOL\",\"SCIENTIST\",\"SCORPION\",\"SCREEN\",\"SCUBA DIVER\",\"SEAL\",\"SERVER\",\"SHADOW\",\"SHAKESPEARE\",\"SHARK\",\"SHIP\",\"SHOE\",\"SHOP\",\"SHOT\",\"SINK\",\"SKYSCRAPER\",\"SLIP\",\"SLUG\",\"SMUGGLER\",\"SNOW\",\"SNOWMAN\",\"SOCK\",\"SOLDIER\",\"SOUL\",\"SOUND\",\"SPACE\",\"SPELL\",\"SPIDER\",\"SPIKE\",\"SPINE\",\"SPOT\",\"SPRING\",\"SPY\",\"SQUARE\",\"STADIUM\",\"STAFF\",\"STAR\",\"STATE\",\"STICK\",\"STOCK\",\"STRAW\",\"STREAM\",\"STRIKE\",\"STRING\",\"SUB\",\"SUIT\",\"SUPERHERO\",\"SWING\",\"SWITCH\",\"TABLE\",\"TABLET\",\"TAG\",\"TAIL\",\"TAP\",\"TEACHER\",\"TELESCOPE\",\"TEMPLE\",\"THEATER\",\"THIEF\",\"THUMB\",\"TICK\",\"TIE\",\"TIME\",\"TOKYO\",\"TOOTH\",\"TORCH\",\"TOWER\",\"TRACK\",\"TRAIN\",\"TRIANGLE\",\"TRIP\",\"TRUNK\",\"TUBE\",\"TURKEY\",\"UNDERTAKER\",\"UNICORN\",\"VACUUM\",\"VAN\",\"VET\",\"WAKE\",\"WALL\",\"WAR\",\"WASHER\",\"WASHINGTON\",\"WATCH\",\"WATER\",\"WAVE\",\"WEB\",\"WELL\",\"WHALE\",\"WHIP\",\"WIND\",\"WITCH\",\"WORM\",\"YARD\"]\n",
    "\n",
    "\n",
    "nltk.download(\"omw-1.4\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "if language == \"spa\":\n",
    "    fasttext.util.download_model('es', if_exists='ignore')  # English\n",
    "else:\n",
    "    fasttext.util.download_model('en', if_exists='ignore')\n",
    "\n",
    "if language == \"spa\":\n",
    "    FAST_TEXT_MODEL = \"cc.es.300.bin\" # Model name in fasttext\n",
    "else:\n",
    "    FAST_TEXT_MODEL = \"cc.en.300.bin\"\n",
    "\n",
    "\n",
    "ft = fasttext.load_model(FAST_TEXT_MODEL)\n",
    "model = load_facebook_model(FAST_TEXT_MODEL)\n",
    "if language == \"spa\":\n",
    "    words = spanish_words \n",
    "else: \n",
    "    words = english_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884caf7",
   "metadata": {},
   "source": [
    "# Medias entre palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00b7db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    return model.wv.similarity(word1, word2)\n",
    "\n",
    "def get_synonyms(word1, lang = 'spa'):\n",
    "    all_synonyms = list(map(lambda x: x.lemma_names(lang), wn.synsets(word1, lang=lang)))\n",
    "    return list(set(itertools.chain(*all_synonyms)))\n",
    "\n",
    "def get_antonyms(word1, lang = 'spa'):\n",
    "    all_lemas = list(map(lambda x: x.lemmas(), wn.synsets(word1, lang=lang)))\n",
    "    all_antonyms_lemas = list(map(lambda x: x.antonyms(), list(itertools.chain(*all_lemas))))\n",
    "    all_antonyms = map(lambda x: x.synset().lemma_names(lang=lang), list(itertools.chain(*all_antonyms_lemas)))\n",
    "    return list(set(itertools.chain(*all_antonyms)))\n",
    "\n",
    "def get_synonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_synonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_synonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    synonyms = list(set(synonyms_word1).intersection(synonyms_word2))\n",
    "    if len(synonyms) !=0:\n",
    "        max_value = max(synonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_number_of_same_synonyms(word1, word2, lang = 'spa'):\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_number_of_same_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    return len(set(antonyms_word1).intersection(antonyms_word2))\n",
    "\n",
    "def get_number_synonyms_vs_antonyms(word1, word2, lang = 'spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    synonyms_word1 = get_synonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    synonyms_word2 = get_synonyms(word2, lang = lang)\n",
    "    return len(set(synonyms_word1).intersection(antonyms_word2)) + len(set(antonyms_word1).intersection(synonyms_word2))\n",
    "\n",
    "def get_antonyms_with_similarity(word1, model, lang='spa'):\n",
    "    return list(map(lambda word2: (word2, get_cosine_similarity(model, word1, word2)), get_antonyms(word1, lang=lang)))\n",
    "\n",
    "def get_max_antonym_similarity_between_words(word1, word2, model, lang='spa'):\n",
    "    antonyms_word1 = get_antonyms(word1, lang = lang)\n",
    "    antonyms_word2 = get_antonyms(word2, lang = lang)\n",
    "    antonyms = list(set(antonyms_word1).intersection(antonyms_word2))\n",
    "    if len(antonyms) != 0:\n",
    "        max_value = max(antonyms)\n",
    "    else:\n",
    "        max_value = 0\n",
    "    max_value = max_value if max_value else 0\n",
    "    return max_value\n",
    "\n",
    "def get_hypernyms_of_synsets(synsets):\n",
    "    hypernyms = list(map(lambda x: x.hypernyms(), synsets))\n",
    "    return list(set(itertools.chain(*hypernyms)))\n",
    "\n",
    "def get_path_similarity(synset1, synset2):\n",
    "    similarity = wn.path_similarity(synset1, synset2)\n",
    "    similarity = similarity if similarity else 0\n",
    "    return similarity\n",
    "\n",
    "def get_first_common_hypernym(word1, word2, lang = 'spa'):\n",
    "    temporal_hypernyms1 = get_hypernyms_of_synsets(wn.synsets(word1, lang=lang))\n",
    "    temporal_hypernyms2 = get_hypernyms_of_synsets(wn.synsets(word2, lang=lang))\n",
    "    hypernyms1 = list(set(temporal_hypernyms1))\n",
    "    hypernyms2 = list(set(temporal_hypernyms2))\n",
    "    while len(set(hypernyms1).intersection(hypernyms2))==0 and (len(temporal_hypernyms1)!=0 or len(temporal_hypernyms2)!=0):\n",
    "        hypernyms1 = list(set(hypernyms1 + temporal_hypernyms1))\n",
    "        hypernyms2 = list(set(hypernyms2 + temporal_hypernyms2))\n",
    "        temporal_hypernyms1 = get_hypernyms_of_synsets(temporal_hypernyms1)\n",
    "        temporal_hypernyms2 = get_hypernyms_of_synsets(temporal_hypernyms2)\n",
    "    if len(set(hypernyms1).intersection(hypernyms2))!=0:\n",
    "        hypernyms = list(set(hypernyms1).intersection(hypernyms2))\n",
    "        possible_hypernyms = list(map(lambda x: max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word1, lang=lang)))) + max(list(map(lambda y: get_path_similarity(x, y), wn.synsets(word2, lang=lang)))),hypernyms))\n",
    "        max_value = max(possible_hypernyms)\n",
    "        hypernym = hypernyms[possible_hypernyms.index(max_value)]\n",
    "        similarity_to_word1 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word1, lang=lang))))\n",
    "        similarity_to_word2 = max(list(map(lambda x: get_path_similarity(hypernyms[possible_hypernyms.index(max_value)],x),wn.synsets(word2, lang=lang))))\n",
    "    else:\n",
    "        hypernym = None\n",
    "        similarity_to_word1 = 0\n",
    "        similarity_to_word2 = 0\n",
    "    return hypernym, similarity_to_word1, similarity_to_word2\n",
    "    \n",
    "    \n",
    "def apply_all_metrics_to_words_df(df, model, word2, lang = 'spa'):\n",
    "    df['similarity'] = df.apply(lambda x: get_cosine_similarity(model, x['words'], word2), axis=1)\n",
    "    df['number_same_synonyms'] = df.apply(lambda x: get_number_of_same_synonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['number_same_antonyms'] = df.apply(lambda x: get_number_of_same_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['synonyms_vs_antonyms'] = df.apply(lambda x: get_number_synonyms_vs_antonyms(x['words'], word2, lang= lang), axis=1)\n",
    "    df['max_similarity_synonym'] = df.apply(lambda x: get_max_synonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['max_similarity_antonym'] = df.apply(lambda x: get_max_antonym_similarity_between_words(x['words'], word2, model, lang=lang), axis=1)\n",
    "    df['distance_common_hypernym'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[1], axis=1)\n",
    "    df['distance_common_hypernym_from_word'] =  df.apply(lambda x: get_first_common_hypernym(x['words'], word2, lang= lang)[2], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_definition(word, lang = 'spa'):\n",
    "    return list(map(lambda x: x.definition(),wn.synsets(word, lang= lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a6cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.es.300.bin'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.download_model('es', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaabf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grado similaridad\n",
    "#Numero de sinonimos en común\n",
    "#Número de antónimos en común\n",
    "#Relación con los sinonimos\n",
    "#Relación con los antónimos\n",
    "#Familia semántica (Hiperonimos)\n",
    "#Número de palabras entre la pista y la evaluada(s)\n",
    "\n",
    "\n",
    "# Implementar distancia de la definiciones\n",
    "# Hacer clustering (jerarquico y k-means)\n",
    "# Implementar bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(words, columns = [\"words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf83b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb01bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_all_metrics_to_words_df(sample_data, model, 'dinero', lang=language)\n",
    "df.index = df.words\n",
    "df = df.drop(['words'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb799d",
   "metadata": {},
   "source": [
    "# Vectores como variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea26a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector(words):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = pd.DataFrame(words, columns = [\"words\"], index=words)\n",
    "    df_with_vectors[column_names] = df_with_vectors.apply(lambda x: list(ft.get_word_vector(x['words'])), axis=1, result_type='expand')\n",
    "    df_with_vectors = df_with_vectors.drop(['words'], axis=1)\n",
    "    return df_with_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd5075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_coordinates_vector_with_clue(words, clue):\n",
    "    column_names = list(map(lambda x: 'var'+str(x),np.arange(0, 300)))\n",
    "    df_with_vectors = get_dataframe_with_coordinates_vector(words)\n",
    "    df_with_vectors_and_clue = pd.concat([df_with_vectors, pd.DataFrame([list(ft.get_word_vector(clue))], index=[clue], columns=column_names)])\n",
    "    return df_with_vectors_and_clue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea89d0e",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b900428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manga' 'látigo' 'cometa' 'fuego' 'llave' 'cromo' 'ronda' 'cadena'\n",
      " 'baile' 'marca' 'arco' 'ola' 'topo' 'pastel' 'ópera' 'obra' 'aire'\n",
      " 'enano' 'teclado' 'capital' 'cólera' 'paracaídas' 'vado' 'cementerio'\n",
      " 'órgano']\n"
     ]
    }
   ],
   "source": [
    "sample_words = np.random.choice(words, size=25, replace=False)\n",
    "print(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(v1, v2):\n",
    "    return np.sqrt(np.sum(np.subtract(v1, v2)**2))\n",
    "\n",
    "def get_words_from_clue(sample_words, clue, number_words, model):\n",
    "    return list(filter(lambda element: element!= clue, list(get_dataframe_from_clue(sample_words, clue, number_words, model)[:number_words+1].index)))\n",
    "    \n",
    "def get_dataframe_from_clue(sample_words, clue, number_words, model):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector_with_clue(sample_words, clue)\n",
    "    kmeans = KMeans(n_clusters = 25 - number_words)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    clue_cluster = kmeans_response.cluster_centers_[df_for_clustering['cluster'][-1]]\n",
    "    distance_to_clue_cluster = list(map(lambda center: get_distance(center, clue_cluster), kmeans_response.cluster_centers_))\n",
    "    df_for_clustering['distance_to_clue_cluster'] = df_for_clustering.apply(lambda cluster: distance_to_clue_cluster[int(cluster['cluster'])], axis=1)\n",
    "    df_for_clustering['distance_to_clue'] = df_for_clustering.apply(lambda row: 1-model.wv.similarity(row.name, clue), axis=1)\n",
    "    return df_for_clustering[['cluster', 'distance_to_clue_cluster', 'distance_to_clue']].sort_values(by=['distance_to_clue_cluster', 'distance_to_clue'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87a59c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_words(cluster, df_for_clustering, team):\n",
    "    return len(df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)])\n",
    "\n",
    "def get_team_words_array(cluster, df_for_clustering, team):\n",
    "    df = df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)]\n",
    "    return np.array(df.index)\n",
    "\n",
    "def get_clue(row, words_in_game):\n",
    "    posible_clues = model.similar_by_vector(row['cluster_info'].cluster_centers_[row['cluster']], topn=26)\n",
    "    counter = 0\n",
    "    while posible_clues[counter][0].lower() in words_in_game:\n",
    "        counter = counter + 1\n",
    "    return posible_clues[counter][0]\n",
    "\n",
    "def get_distance_team_words(clue, words_array):\n",
    "    distance = list(map(lambda word: 1-model.wv.similarity(clue,word), words_array))\n",
    "    return np.sum(distance)    \n",
    "\n",
    "def get_distance_with_all_words(word, df_with_words):\n",
    "    df_with_words['distance_to_word'] = df_with_words.apply(lambda row: 1-model.wv.similarity(row.name, word), axis=1)\n",
    "    return np.sum(df_with_words['distance_to_word'])\n",
    "    \n",
    "def get_intracluster_distance(df):\n",
    "    if not df.empty:\n",
    "        df['row_number'] = np.arange(len(df))\n",
    "        df['sum_distance_to_words'] = df.apply(lambda row: get_distance_with_all_words(row.name,df[int(row['row_number']):]), axis=1)\n",
    "        return np.sum(df['sum_distance_to_words'])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_intracluster_distance_all(cluster, df_for_clustering):\n",
    "    df_with_cluster_words = df_for_clustering.loc[df_for_clustering['cluster']==cluster]\n",
    "    return get_intracluster_distance(df_with_cluster_words)\n",
    "\n",
    "def get_intracluster_distance_for_team(cluster, df_for_clustering, team):\n",
    "    df_with_team_cluster_words = df_for_clustering.loc[(df_for_clustering['cluster']==cluster) & (df_for_clustering['team']==team)]\n",
    "    return get_intracluster_distance(df_with_team_cluster_words)\n",
    "\n",
    "def get_clusters_with_info(df, number_of_clusters, words_in_game):\n",
    "    df_for_clustering = get_dataframe_with_coordinates_vector(df['words'])\n",
    "    kmeans = KMeans(n_clusters= number_of_clusters)\n",
    "    kmeans_response = kmeans.fit(df_for_clustering)\n",
    "    df_for_clustering['team'] = df['team']\n",
    "    df_for_clustering['cluster'] = kmeans_response.labels_\n",
    "    #df_for_clustering.groupby(level='cluster').agg({'team_words':, 'enemy_words':, 'white_words':, 'forbidden_word':, 'Intracluster_distance':, 'team_words_distance':, 'team_words_distance_to_center'::})\n",
    "    result_df = pd.DataFrame(range(0,number_of_clusters), columns = ['cluster'], index=range(0,number_of_clusters))\n",
    "    result_df['cluster_info'] = kmeans_response\n",
    "    result_df['number_of_clusters'] = number_of_clusters\n",
    "    result_df['team_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    result_df['enemy_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'red'), axis=1)\n",
    "    result_df['white_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'white'), axis=1)\n",
    "    result_df['forbidden_words'] = result_df.apply(lambda row: get_team_words(row['cluster'], df_for_clustering, 'black'), axis=1)\n",
    "    result_df = result_df.loc[result_df['team_words']>0]\n",
    "    result_df['team_words_array'] = result_df.apply(lambda row: get_team_words_array(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    result_df['enemy_words_array'] = result_df.apply(lambda row: get_team_words_array(row['cluster'], df_for_clustering, 'red'), axis=1)\n",
    "    result_df['white_words_array'] = result_df.apply(lambda row: get_team_words_array(row['cluster'], df_for_clustering, 'white'), axis=1)\n",
    "    result_df['forbidden_words_array'] = result_df.apply(lambda row: get_team_words_array(row['cluster'], df_for_clustering, 'black'), axis=1)\n",
    "    result_df['clue'] = result_df.apply(lambda row: get_clue(row, words_in_game), axis=1)\n",
    "    result_df['distance_to_team_words'] = result_df.apply(lambda row: get_distance_team_words(row['clue'], row['team_words_array']), axis=1)\n",
    "    result_df['distance_to_enemy_words'] = result_df.apply(lambda row: get_distance_team_words(row['clue'], row['enemy_words_array']), axis=1)\n",
    "    result_df['distance_to_white_words'] = result_df.apply(lambda row: get_distance_team_words(row['clue'], row['white_words_array']), axis=1)\n",
    "    result_df['distance_to_forbidden_words'] = result_df.apply(lambda row: get_distance_team_words(row['clue'], row['forbidden_words_array']), axis=1)\n",
    "    result_df['intracluster_distance'] = result_df.apply(lambda row: get_intracluster_distance_all(row['clue'], df_for_clustering), axis=1)\n",
    "    result_df['intracluster_distance_team'] = result_df.apply(lambda row: get_intracluster_distance_for_team(row['cluster'], df_for_clustering, 'blue'), axis=1)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372b472",
   "metadata": {},
   "source": [
    "# Give clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83f7db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "dataframe_words_teams = pd.DataFrame(sample_words, columns = [\"words\"], index=sample_words)\n",
    "dataframe_words_teams['team'] = ['blue']*8 + ['red']*9 + ['black'] + ['white']*7\n",
    "\n",
    "final_df = get_clusters_with_info(dataframe_words_teams, 3, sample_words)\n",
    "for number_clusters in range(4, 26):\n",
    "    final_df = pd.concat([final_df, get_clusters_with_info(dataframe_words_teams, number_clusters, sample_words)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91a5324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_info</th>\n",
       "      <th>number_of_clusters</th>\n",
       "      <th>team_words</th>\n",
       "      <th>enemy_words</th>\n",
       "      <th>white_words</th>\n",
       "      <th>forbidden_words</th>\n",
       "      <th>team_words_array</th>\n",
       "      <th>enemy_words_array</th>\n",
       "      <th>white_words_array</th>\n",
       "      <th>forbidden_words_array</th>\n",
       "      <th>clue</th>\n",
       "      <th>distance_to_team_words</th>\n",
       "      <th>distance_to_enemy_words</th>\n",
       "      <th>distance_to_white_words</th>\n",
       "      <th>distance_to_forbidden_words</th>\n",
       "      <th>intracluster_distance</th>\n",
       "      <th>intracluster_distance_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>KMeans(n_clusters=3)</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[manga, látigo, cometa, fuego, llave, cromo, r...</td>\n",
       "      <td>[baile, marca, arco, topo, pastel, ópera, obra...</td>\n",
       "      <td>[teclado, capital, cólera, paracaídas, cemente...</td>\n",
       "      <td>[enano]</td>\n",
       "      <td>arquito</td>\n",
       "      <td>5.939938</td>\n",
       "      <td>5.667611</td>\n",
       "      <td>4.630406</td>\n",
       "      <td>0.635698</td>\n",
       "      <td>0</td>\n",
       "      <td>22.604122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KMeans(n_clusters=4)</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[manga, látigo, cometa, fuego, llave, cromo, r...</td>\n",
       "      <td>[baile, marca, arco, topo, pastel, aire]</td>\n",
       "      <td>[teclado, capital, cólera, paracaídas, cemente...</td>\n",
       "      <td>[enano]</td>\n",
       "      <td>arquito</td>\n",
       "      <td>5.939938</td>\n",
       "      <td>4.047657</td>\n",
       "      <td>4.630406</td>\n",
       "      <td>0.635698</td>\n",
       "      <td>0</td>\n",
       "      <td>22.604122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>KMeans(n_clusters=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[llave]</td>\n",
       "      <td>[ópera, obra]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>pieza</td>\n",
       "      <td>0.555931</td>\n",
       "      <td>1.107097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>KMeans(n_clusters=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[manga, látigo, cometa, fuego, cromo, ronda, c...</td>\n",
       "      <td>[baile, marca, topo, pastel, aire]</td>\n",
       "      <td>[teclado, capital, cólera, paracaídas, cemente...</td>\n",
       "      <td>[enano]</td>\n",
       "      <td>supercañón</td>\n",
       "      <td>4.964260</td>\n",
       "      <td>3.660099</td>\n",
       "      <td>4.611434</td>\n",
       "      <td>0.604501</td>\n",
       "      <td>0</td>\n",
       "      <td>17.312134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>KMeans(n_clusters=6)</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[manga, látigo, cometa, fuego, llave, cromo, r...</td>\n",
       "      <td>[baile, marca, topo, pastel, ópera]</td>\n",
       "      <td>[teclado, capital, cólera, paracaídas, cemente...</td>\n",
       "      <td>[enano]</td>\n",
       "      <td>supercañón</td>\n",
       "      <td>5.739744</td>\n",
       "      <td>3.756223</td>\n",
       "      <td>4.611434</td>\n",
       "      <td>0.604501</td>\n",
       "      <td>0</td>\n",
       "      <td>22.604122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10</td>\n",
       "      <td>KMeans(n_clusters=25)</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[llave]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>llaves</td>\n",
       "      <td>0.247762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>13</td>\n",
       "      <td>KMeans(n_clusters=25)</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[manga]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>mangas</td>\n",
       "      <td>0.250713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>14</td>\n",
       "      <td>KMeans(n_clusters=25)</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[fuego]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>fuego.El</td>\n",
       "      <td>0.283438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>17</td>\n",
       "      <td>KMeans(n_clusters=25)</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[cadena]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cadenas</td>\n",
       "      <td>0.254539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>18</td>\n",
       "      <td>KMeans(n_clusters=25)</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[cometa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>cometas</td>\n",
       "      <td>0.278779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster           cluster_info  number_of_clusters  team_words  \\\n",
       "0          1   KMeans(n_clusters=3)                   3           8   \n",
       "1          1   KMeans(n_clusters=4)                   4           8   \n",
       "2          0   KMeans(n_clusters=5)                   5           1   \n",
       "3          1   KMeans(n_clusters=5)                   5           7   \n",
       "4          0   KMeans(n_clusters=6)                   6           8   \n",
       "..       ...                    ...                 ...         ...   \n",
       "115       10  KMeans(n_clusters=25)                  25           1   \n",
       "116       13  KMeans(n_clusters=25)                  25           1   \n",
       "117       14  KMeans(n_clusters=25)                  25           1   \n",
       "118       17  KMeans(n_clusters=25)                  25           1   \n",
       "119       18  KMeans(n_clusters=25)                  25           1   \n",
       "\n",
       "     enemy_words  white_words  forbidden_words  \\\n",
       "0              8            6                1   \n",
       "1              6            6                1   \n",
       "2              2            0                0   \n",
       "3              5            6                1   \n",
       "4              5            6                1   \n",
       "..           ...          ...              ...   \n",
       "115            0            0                0   \n",
       "116            0            0                0   \n",
       "117            0            0                0   \n",
       "118            0            0                0   \n",
       "119            0            0                0   \n",
       "\n",
       "                                      team_words_array  \\\n",
       "0    [manga, látigo, cometa, fuego, llave, cromo, r...   \n",
       "1    [manga, látigo, cometa, fuego, llave, cromo, r...   \n",
       "2                                              [llave]   \n",
       "3    [manga, látigo, cometa, fuego, cromo, ronda, c...   \n",
       "4    [manga, látigo, cometa, fuego, llave, cromo, r...   \n",
       "..                                                 ...   \n",
       "115                                            [llave]   \n",
       "116                                            [manga]   \n",
       "117                                            [fuego]   \n",
       "118                                           [cadena]   \n",
       "119                                           [cometa]   \n",
       "\n",
       "                                     enemy_words_array  \\\n",
       "0    [baile, marca, arco, topo, pastel, ópera, obra...   \n",
       "1             [baile, marca, arco, topo, pastel, aire]   \n",
       "2                                        [ópera, obra]   \n",
       "3                   [baile, marca, topo, pastel, aire]   \n",
       "4                  [baile, marca, topo, pastel, ópera]   \n",
       "..                                                 ...   \n",
       "115                                                 []   \n",
       "116                                                 []   \n",
       "117                                                 []   \n",
       "118                                                 []   \n",
       "119                                                 []   \n",
       "\n",
       "                                     white_words_array forbidden_words_array  \\\n",
       "0    [teclado, capital, cólera, paracaídas, cemente...               [enano]   \n",
       "1    [teclado, capital, cólera, paracaídas, cemente...               [enano]   \n",
       "2                                                   []                    []   \n",
       "3    [teclado, capital, cólera, paracaídas, cemente...               [enano]   \n",
       "4    [teclado, capital, cólera, paracaídas, cemente...               [enano]   \n",
       "..                                                 ...                   ...   \n",
       "115                                                 []                    []   \n",
       "116                                                 []                    []   \n",
       "117                                                 []                    []   \n",
       "118                                                 []                    []   \n",
       "119                                                 []                    []   \n",
       "\n",
       "           clue  distance_to_team_words  distance_to_enemy_words  \\\n",
       "0       arquito                5.939938                 5.667611   \n",
       "1       arquito                5.939938                 4.047657   \n",
       "2         pieza                0.555931                 1.107097   \n",
       "3    supercañón                4.964260                 3.660099   \n",
       "4    supercañón                5.739744                 3.756223   \n",
       "..          ...                     ...                      ...   \n",
       "115      llaves                0.247762                 0.000000   \n",
       "116      mangas                0.250713                 0.000000   \n",
       "117    fuego.El                0.283438                 0.000000   \n",
       "118     cadenas                0.254539                 0.000000   \n",
       "119     cometas                0.278779                 0.000000   \n",
       "\n",
       "     distance_to_white_words  distance_to_forbidden_words  \\\n",
       "0                   4.630406                     0.635698   \n",
       "1                   4.630406                     0.635698   \n",
       "2                   0.000000                     0.000000   \n",
       "3                   4.611434                     0.604501   \n",
       "4                   4.611434                     0.604501   \n",
       "..                       ...                          ...   \n",
       "115                 0.000000                     0.000000   \n",
       "116                 0.000000                     0.000000   \n",
       "117                 0.000000                     0.000000   \n",
       "118                 0.000000                     0.000000   \n",
       "119                 0.000000                     0.000000   \n",
       "\n",
       "     intracluster_distance  intracluster_distance_team  \n",
       "0                        0                   22.604122  \n",
       "1                        0                   22.604122  \n",
       "2                        0                    0.000000  \n",
       "3                        0                   17.312134  \n",
       "4                        0                   22.604122  \n",
       "..                     ...                         ...  \n",
       "115                      0                    0.000000  \n",
       "116                      0                    0.000000  \n",
       "117                      0                    0.000000  \n",
       "118                      0                    0.000000  \n",
       "119                      0                    0.000000  \n",
       "\n",
       "[120 rows x 18 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1cddb",
   "metadata": {},
   "source": [
    "# Guess words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d23215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "clue='FOOTBALL'\n",
    "number_words = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "287b5fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paracaídas', 'teclado']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_clue(sample_words, clue, number_words, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a209c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>distance_to_clue_cluster</th>\n",
       "      <th>distance_to_clue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FOOTBALL</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paracaídas</th>\n",
       "      <td>5</td>\n",
       "      <td>0.931409</td>\n",
       "      <td>0.882143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teclado</th>\n",
       "      <td>5</td>\n",
       "      <td>0.931409</td>\n",
       "      <td>0.912381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital</th>\n",
       "      <td>5</td>\n",
       "      <td>0.931409</td>\n",
       "      <td>0.967473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cementerio</th>\n",
       "      <td>5</td>\n",
       "      <td>0.931409</td>\n",
       "      <td>1.025812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marca</th>\n",
       "      <td>19</td>\n",
       "      <td>1.209058</td>\n",
       "      <td>0.887344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cadena</th>\n",
       "      <td>21</td>\n",
       "      <td>1.237949</td>\n",
       "      <td>0.916052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pastel</th>\n",
       "      <td>18</td>\n",
       "      <td>1.283994</td>\n",
       "      <td>1.012201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>órgano</th>\n",
       "      <td>1</td>\n",
       "      <td>1.301080</td>\n",
       "      <td>0.960347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>látigo</th>\n",
       "      <td>20</td>\n",
       "      <td>1.311986</td>\n",
       "      <td>1.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cometa</th>\n",
       "      <td>4</td>\n",
       "      <td>1.314067</td>\n",
       "      <td>0.950417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cromo</th>\n",
       "      <td>10</td>\n",
       "      <td>1.343723</td>\n",
       "      <td>0.841268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ronda</th>\n",
       "      <td>0</td>\n",
       "      <td>1.393798</td>\n",
       "      <td>0.981284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enano</th>\n",
       "      <td>16</td>\n",
       "      <td>1.396163</td>\n",
       "      <td>0.987564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cólera</th>\n",
       "      <td>12</td>\n",
       "      <td>1.404947</td>\n",
       "      <td>1.087467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manga</th>\n",
       "      <td>15</td>\n",
       "      <td>1.428598</td>\n",
       "      <td>0.903489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baile</th>\n",
       "      <td>17</td>\n",
       "      <td>1.430288</td>\n",
       "      <td>0.987933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuego</th>\n",
       "      <td>2</td>\n",
       "      <td>1.439508</td>\n",
       "      <td>0.980646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llave</th>\n",
       "      <td>13</td>\n",
       "      <td>1.459643</td>\n",
       "      <td>1.012156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obra</th>\n",
       "      <td>11</td>\n",
       "      <td>1.538072</td>\n",
       "      <td>1.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ópera</th>\n",
       "      <td>14</td>\n",
       "      <td>1.554670</td>\n",
       "      <td>0.992265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topo</th>\n",
       "      <td>7</td>\n",
       "      <td>1.575970</td>\n",
       "      <td>0.975963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aire</th>\n",
       "      <td>8</td>\n",
       "      <td>1.608360</td>\n",
       "      <td>0.961254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arco</th>\n",
       "      <td>9</td>\n",
       "      <td>1.802731</td>\n",
       "      <td>0.992914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vado</th>\n",
       "      <td>6</td>\n",
       "      <td>2.041722</td>\n",
       "      <td>1.061013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ola</th>\n",
       "      <td>3</td>\n",
       "      <td>2.528630</td>\n",
       "      <td>0.955246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cluster  distance_to_clue_cluster  distance_to_clue\n",
       "FOOTBALL         22                  0.000000          0.000000\n",
       "paracaídas        5                  0.931409          0.882143\n",
       "teclado           5                  0.931409          0.912381\n",
       "capital           5                  0.931409          0.967473\n",
       "cementerio        5                  0.931409          1.025812\n",
       "marca            19                  1.209058          0.887344\n",
       "cadena           21                  1.237949          0.916052\n",
       "pastel           18                  1.283994          1.012201\n",
       "órgano            1                  1.301080          0.960347\n",
       "látigo           20                  1.311986          1.005219\n",
       "cometa            4                  1.314067          0.950417\n",
       "cromo            10                  1.343723          0.841268\n",
       "ronda             0                  1.393798          0.981284\n",
       "enano            16                  1.396163          0.987564\n",
       "cólera           12                  1.404947          1.087467\n",
       "manga            15                  1.428598          0.903489\n",
       "baile            17                  1.430288          0.987933\n",
       "fuego             2                  1.439508          0.980646\n",
       "llave            13                  1.459643          1.012156\n",
       "obra             11                  1.538072          1.018237\n",
       "ópera            14                  1.554670          0.992265\n",
       "topo              7                  1.575970          0.975963\n",
       "aire              8                  1.608360          0.961254\n",
       "arco              9                  1.802731          0.992914\n",
       "vado              6                  2.041722          1.061013\n",
       "ola               3                  2.528630          0.955246"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_dataframe_from_clue(sample_words, clue, number_words, model)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-codenames",
   "language": "python",
   "name": "py-codenames"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
